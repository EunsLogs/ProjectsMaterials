{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Library\" data-toc-modified-id=\"Library-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Library</a></span></li><li><span><a href=\"#Data-Load\" data-toc-modified-id=\"Data-Load-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Load</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Missing-Value\" data-toc-modified-id=\"1.-Missing-Value-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>1. Missing Value</a></span></li><li><span><a href=\"#2.-파생변수\" data-toc-modified-id=\"2.-파생변수-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>2. 파생변수</a></span><ul class=\"toc-item\"><li><span><a href=\"#(1)-주문량-:-취급액/판매단가\" data-toc-modified-id=\"(1)-주문량-:-취급액/판매단가-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>(1) 주문량 : 취급액/판매단가</a></span></li><li><span><a href=\"#(2)-날짜정보-:-'방송일시'-->-월,-일,-요일,-시간대-등의-정보로-바꾸기\" data-toc-modified-id=\"(2)-날짜정보-:-'방송일시'-->-월,-일,-요일,-시간대-등의-정보로-바꾸기-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>(2) 날짜정보 : '방송일시' -&gt; 월, 일, 요일, 시간대 등의 정보로 바꾸기</a></span></li><li><span><a href=\"#(2)-2-계절-정보,-주말(공휴일)-정보-추가\" data-toc-modified-id=\"(2)-2-계절-정보,-주말(공휴일)-정보-추가-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>(2)-2 계절 정보, 주말(공휴일) 정보 추가</a></span></li><li><span><a href=\"#(2)-3-Business_day-추가\" data-toc-modified-id=\"(2)-3-Business_day-추가-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>(2)-3 Business_day 추가</a></span></li><li><span><a href=\"#(3)-날씨-데이터-결합\" data-toc-modified-id=\"(3)-날씨-데이터-결합-2.2.5\"><span class=\"toc-item-num\">2.2.5&nbsp;&nbsp;</span>(3) 날씨 데이터 결합</a></span></li><li><span><a href=\"#(4)-프라임타임\" data-toc-modified-id=\"(4)-프라임타임-2.2.6\"><span class=\"toc-item-num\">2.2.6&nbsp;&nbsp;</span>(4) 프라임타임</a></span><ul class=\"toc-item\"><li><span><a href=\"#(4)-3.-요일+상품군별-프라임타임-&amp;-스윙타임\" data-toc-modified-id=\"(4)-3.-요일+상품군별-프라임타임-&amp;-스윙타임-2.2.6.1\"><span class=\"toc-item-num\">2.2.6.1&nbsp;&nbsp;</span>(4)-3. 요일+상품군별 프라임타임 &amp; 스윙타임</a></span></li></ul></li><li><span><a href=\"#(5)-시청률-통계량\" data-toc-modified-id=\"(5)-시청률-통계량-2.2.7\"><span class=\"toc-item-num\">2.2.7&nbsp;&nbsp;</span>(5) 시청률 통계량</a></span></li><li><span><a href=\"#(6)-판매단가-binning\" data-toc-modified-id=\"(6)-판매단가-binning-2.2.8\"><span class=\"toc-item-num\">2.2.8&nbsp;&nbsp;</span>(6) 판매단가 binning</a></span></li><li><span><a href=\"#(7)-방송순서\" data-toc-modified-id=\"(7)-방송순서-2.2.9\"><span class=\"toc-item-num\">2.2.9&nbsp;&nbsp;</span>(7) 방송순서</a></span></li><li><span><a href=\"#(8)-실제노출\" data-toc-modified-id=\"(8)-실제노출-2.2.10\"><span class=\"toc-item-num\">2.2.10&nbsp;&nbsp;</span>(8) 실제노출</a></span></li><li><span><a href=\"#(9)-Brand-Name\" data-toc-modified-id=\"(9)-Brand-Name-2.2.11\"><span class=\"toc-item-num\">2.2.11&nbsp;&nbsp;</span>(9) Brand Name</a></span></li><li><span><a href=\"#(10)-상품명-중분류\" data-toc-modified-id=\"(10)-상품명-중분류-2.2.12\"><span class=\"toc-item-num\">2.2.12&nbsp;&nbsp;</span>(10) 상품명 중분류</a></span></li><li><span><a href=\"#(11)-브랜드별,-중분류별-클러스터링\" data-toc-modified-id=\"(11)-브랜드별,-중분류별-클러스터링-2.2.13\"><span class=\"toc-item-num\">2.2.13&nbsp;&nbsp;</span>(11) 브랜드별, 중분류별 클러스터링</a></span></li><li><span><a href=\"#(12)-train에-존재하지만-test에는-존재하지-않는-마더코드,-상품코드를-브랜드,-중분류로-비교-후-대체\" data-toc-modified-id=\"(12)-train에-존재하지만-test에는-존재하지-않는-마더코드,-상품코드를-브랜드,-중분류로-비교-후-대체-2.2.14\"><span class=\"toc-item-num\">2.2.14&nbsp;&nbsp;</span>(12) train에 존재하지만 test에는 존재하지 않는 마더코드, 상품코드를 브랜드, 중분류로 비교 후 대체</a></span></li></ul></li></ul></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Modeling</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Tyj_Q6x5m24v",
    "outputId": "626d09a0-41a2-4305-f31d-e72a6c56d4ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YYEw8CfE4aw"
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "9MhuGcLUmPv-",
    "outputId": "3a04aa3e-5477-437f-9b8d-0869fa8ea21c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting distance\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/1a/883e47df323437aefa0d0a92ccfb38895d9416bd0b56262c2e46a47767b8/Distance-0.1.3.tar.gz (180kB)\n",
      "\r",
      "\u001b[K     |█▉                              | 10kB 17.3MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 20kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 30kB 6.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 40kB 5.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 51kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 61kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 71kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 81kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 92kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 102kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 112kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 122kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 133kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 143kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 153kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 163kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 174kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 184kB 4.8MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: distance\n",
      "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for distance: filename=Distance-0.1.3-cp36-none-any.whl size=16262 sha256=071df39d9e3de0aa7369926a55fdd143d6c3d0ae0a36b1dadbcd3a37602412fd\n",
      "  Stored in directory: /root/.cache/pip/wheels/d5/aa/e1/dbba9e7b6d397d645d0f12db1c66dbae9c5442b39b001db18e\n",
      "Successfully built distance\n",
      "Installing collected packages: distance\n",
      "Successfully installed distance-0.1.3\n",
      "Collecting leven\n",
      "  Downloading https://files.pythonhosted.org/packages/73/02/37084115516cfd595ee2f9a873fffe8b85c6b1538523ff6a8b8dd7ff7d46/leven-1.0.4.tar.gz\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from leven) (1.15.0)\n",
      "Collecting nose\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 11.3MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: leven\n",
      "  Building wheel for leven (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for leven: filename=leven-1.0.4-cp36-cp36m-linux_x86_64.whl size=54666 sha256=766cc6daae494c3b951f5d5778dd91eb5c3e6f8da05243211bfbdfb5c52ff442\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/64/a5/439db671d666a50f3b3cebd2dcab3fbbab02785adf58e47552\n",
      "Successfully built leven\n",
      "Installing collected packages: nose, leven\n",
      "Successfully installed leven-1.0.4 nose-1.3.7\n"
     ]
    }
   ],
   "source": [
    "!pip install distance\n",
    "!pip install leven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "RAI83PKsciBE",
    "outputId": "310e076b-3e97-4eff-81c5-206bae2c740f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import distance as dist\n",
    "from leven import levenshtein\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8ModWgUFGPO"
   },
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1zw1icNQ9WnF"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_excel('./01_제공데이터/2020 빅콘테스트 데이터분석분야-챔피언리그_2019년 실적데이터_v1_200818.xlsx', header=1)\n",
    "rating_df = pd.read_excel('./01_제공데이터/2020 빅콘테스트 데이터분석분야-챔피언리그_시청률 데이터.xlsx', header=1)\n",
    "test_df = pd.read_excel('./02_평가데이터/2020 빅콘테스트 데이터분석분야-챔피언리그_2020년 6월 판매실적예측데이터(평가데이터).xlsx', header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AN4bZP2bciCH"
   },
   "source": [
    "---\n",
    "\n",
    "## 1. Missing Value\n",
    "- 노출(분) : 같은 시간대 여러 상품코드가 판매된 경우 결측치\n",
    "- 취급액 : 0원(보험, 투어와 같은 무형자산)은 판매 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "f5zrvctEciCr"
   },
   "outputs": [],
   "source": [
    "idx = train_df[train_df['노출(분)'].isna()].index\n",
    "for i in idx:\n",
    "    train_df.loc[i, '노출(분)'] = train_df.loc[i-1, '노출(분)']\n",
    "idx2 = test_df[test_df['노출(분)'].isna()].index\n",
    "for i in idx2:\n",
    "    test_df.loc[i, '노출(분)'] = test_df.loc[i-1, '노출(분)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DK-DV5IlciDK"
   },
   "source": [
    "---\n",
    "\n",
    "## 2. 파생변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZgnCrEdciDd"
   },
   "source": [
    "### (1) 주문량 : 취급액/판매단가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-CN8vUkJciDe"
   },
   "outputs": [],
   "source": [
    "train_df['주문량'] = train_df['취급액']/ train_df['판매단가']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLiNo_uYciDM"
   },
   "source": [
    "### (2) 날짜정보 : '방송일시' -> 월, 일, 요일, 시간대 등의 정보로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "lV5KobfI72xR"
   },
   "outputs": [],
   "source": [
    "train_df['일시'] = train_df['방송일시'].dt.floor('H')\n",
    "train_df['month'] = train_df['방송일시'].dt.month\n",
    "train_df['day'] = train_df['방송일시'].dt.day\n",
    "train_df['hour'] = train_df['방송일시'].dt.hour\n",
    "train_df['minute'] = train_df['방송일시'].dt.minute\n",
    "train_df['weekday'] = train_df['방송일시'].dt.weekday\n",
    "train_df['weekofyear'] = train_df['방송일시'].dt.weekofyear\n",
    "\n",
    "test_df['일시'] = test_df['방송일시'].dt.floor('H')\n",
    "test_df['month'] = test_df['방송일시'].dt.month\n",
    "test_df['day'] = test_df['방송일시'].dt.day\n",
    "test_df['hour'] = test_df['방송일시'].dt.hour\n",
    "test_df['minute'] = test_df['방송일시'].dt.minute\n",
    "test_df['weekday'] = test_df['방송일시'].dt.weekday\n",
    "test_df['weekofyear'] = test_df['방송일시'].dt.weekofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8GKrshhRjId"
   },
   "source": [
    "### (2)-2 계절 정보, 주말(공휴일) 정보 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "g8EXfAaQRNVt"
   },
   "outputs": [],
   "source": [
    "def sea(x):\n",
    "    if (x < 3) | (x == 12):\n",
    "        return 3\n",
    "    elif (x >= 3) & (x < 6):\n",
    "        return 0\n",
    "    elif (x >= 6) & (x < 9):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "train_df['season'] = train_df['month'].map(sea)\n",
    "test_df['season'] = test_df['month'].map(sea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "bF7GW49ARTRe"
   },
   "outputs": [],
   "source": [
    "holiday_2019 = [datetime.date(2019, 1, 1), datetime.date(2019, 2, 4), datetime.date(2019, 2, 5), datetime.date(2019, 2, 6),\n",
    "                datetime.date(2019, 3, 1), datetime.date(2019, 5, 5), datetime.date(2019, 5, 6), datetime.date(2019, 5, 12),\n",
    "                datetime.date(2019, 4, 10), datetime.date(2019, 6, 6), datetime.date(2019, 8, 15), datetime.date(2019, 9, 12),\n",
    "                datetime.date(2019, 9, 13), datetime.date(2019, 9 ,14), datetime.date(2019, 10, 3), datetime.date(2019, 10, 9),\n",
    "                datetime.date(2019, 12, 25)]\n",
    "holiday_2020 = [datetime.date(2020, 6, 6)]\n",
    "\n",
    "train_df['holiday'] = train_df['방송일시'].dt.date.map(lambda x: 1 if x in holiday_2019 else 0)\n",
    "test_df['holiday'] = test_df['방송일시'].dt.date.map(lambda x: 1 if x in holiday_2020 else 0)\n",
    "train_df['holiday'][train_df['weekday'] >= 5] = 1\n",
    "test_df['holiday'][test_df['weekday'] >= 5] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqXXJPNmTwad"
   },
   "source": [
    "### (2)-3 Business_day 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "XOYFTauQTknO"
   },
   "outputs": [],
   "source": [
    "train_df['business_day'] = 0\n",
    "for i in train_df.index:\n",
    "  if (train_df.loc[i, 'day'] == 1) & (train_df.loc[i, 'hour'] <= 2):\n",
    "    if train_df.loc[i, 'month'] in [1, 2, 4, 6, 8, 9, 11]:\n",
    "      train_df.loc[i, 'business_day'] = 31\n",
    "    elif train_df.loc[i, 'month'] == 3:\n",
    "      train_df.loc[i, 'business_day'] = 28\n",
    "    else:\n",
    "      train_df.loc[i, 'business_day'] = 30\n",
    "  elif train_df.loc[i, 'hour'] <= 2:\n",
    "    train_df.loc[i, 'business_day'] = train_df.loc[i, 'day'] - 1\n",
    "  else:\n",
    "    train_df.loc[i, 'business_day'] = train_df.loc[i, 'day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "OhrNuSJEaGRz"
   },
   "outputs": [],
   "source": [
    "test_df['business_day'] = 0\n",
    "for i in test_df.index:\n",
    "  if (test_df.loc[i, 'day'] == 1) & (test_df.loc[i, 'hour'] <= 2):\n",
    "    test_df.loc[i, 'business_day'] = 30\n",
    "  elif test_df.loc[i, 'hour'] <= 2:\n",
    "    test_df.loc[i, 'business_day'] = test_df.loc[i, 'day'] - 1\n",
    "  else:\n",
    "    test_df.loc[i, 'business_day'] = test_df.loc[i, 'day']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPQRfbH7rci6"
   },
   "source": [
    "### (3) 날씨 데이터 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Ynub-vPurbxW"
   },
   "outputs": [],
   "source": [
    "wea_2019 = pd.read_csv('./03_외부데이터/wea_2019.csv', encoding='euc-kr', engine='python')\n",
    "wea_2020 = pd.read_csv('./03_외부데이터/wea_2020.csv', encoding='euc-kr', engine='python')\n",
    "mis_2019 = pd.read_csv('./03_외부데이터/mis_2019.csv', encoding='euc-kr', engine='python')\n",
    "mis_2020 = pd.read_csv('./03_외부데이터/mis_2020.csv', encoding='euc-kr', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "tpq3pfdZr3sI"
   },
   "outputs": [],
   "source": [
    "wea_2019['일시'] = wea_2019['일시'].astype('datetime64[ns]')\n",
    "wea_2020['일시'] = wea_2020['일시'].astype('datetime64[ns]')\n",
    "mis_2019['일시'] = mis_2019['일시'].astype('datetime64[ns]')\n",
    "mis_2020['일시'] = mis_2020['일시'].astype('datetime64[ns]')\n",
    "wea_2019['강수량'] = wea_2019['강수량'].fillna(0)\n",
    "wea_2020['강수량'] = wea_2020['강수량'].fillna(0)\n",
    "wea_2019.drop('지점', axis=1, inplace=True)\n",
    "wea_2020.drop('지점', axis=1, inplace=True)\n",
    "mis_2019.drop('지점', axis=1, inplace=True)\n",
    "mis_2020.drop('지점', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "lpV7NwzWr3yI"
   },
   "outputs": [],
   "source": [
    "# 2019날씨\n",
    "l1 = list(wea_2019['지점명'].unique())\n",
    "w1 = pd.DataFrame(pd.Series(pd.date_range('2019-01-01 06:00:00', '2020-01-01 01:00:00', freq='H')), columns=['일시'])\n",
    "for i in l1:\n",
    "  w2 = wea_2019[wea_2019['지점명'] == i].drop('지점명', axis=1)\n",
    "  w1 = pd.merge(w1, w2, how='left', on='일시', suffixes=('', '_' + i))\n",
    "w1 = w1.rename({'기온': '기온_파주', '강수량': '강수량_파주', '풍속': '풍속_파주', '습도': '습도_파주'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9UeHcg59sDwX"
   },
   "outputs": [],
   "source": [
    "# 2020날씨\n",
    "w1_1 = pd.DataFrame(pd.Series(pd.date_range('2020-06-01 06:00:00', '2020-07-01 01:00:00', freq='H')), columns=['일시'])\n",
    "for i in l1:\n",
    "  w2 = wea_2020[wea_2020['지점명'] == i].drop('지점명', axis=1)\n",
    "  w1_1 = pd.merge(w1_1, w2, how='left', on='일시', suffixes=('', '_' + i))\n",
    "w1_1 = w1_1.rename({'기온': '기온_파주', '강수량': '강수량_파주', '풍속': '풍속_파주', '습도': '습도_파주'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "UPrNX5bgsDqX"
   },
   "outputs": [],
   "source": [
    "# 2019 미세먼지\n",
    "l1 = list(mis_2019['지점명'].unique())\n",
    "w3 = pd.DataFrame(pd.Series(pd.date_range('2019-01-01 06:00:00', '2020-01-01 01:00:00', freq='H')), columns=['일시'])\n",
    "for i in l1:\n",
    "  w4 = mis_2019[mis_2019['지점명'] == i].drop('지점명', axis=1)\n",
    "  w3 = pd.merge(w3, w4, how='left', on='일시', suffixes=('', '_' + i))\n",
    "w3 = w3.rename({'미세먼지': '미세먼지_속초'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "SYAOLdRKsDo8"
   },
   "outputs": [],
   "source": [
    "# 2020미세먼지\n",
    "w3_1 = pd.DataFrame(pd.Series(pd.date_range('2020-06-01 06:00:00', '2020-07-01 01:00:00', freq='H')), columns=['일시'])\n",
    "for i in l1:\n",
    "  w4 = mis_2020[mis_2020['지점명'] == i].drop('지점명', axis=1)\n",
    "  w3_1 = pd.merge(w3_1, w4, how='left', on='일시', suffixes=('', '_' + i))\n",
    "w3_1 = w3_1.rename({'미세먼지': '미세먼지_속초'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "95_x9WBasDnc"
   },
   "outputs": [],
   "source": [
    "# 날씨, 미세먼지 결합\n",
    "weather_2019 = pd.merge(w1, w3, how='left', on='일시').drop(['기온_세종', '강수량_세종', '풍속_세종', '습도_세종', '미세먼지_속초'], axis=1)\n",
    "weather_2020 = pd.merge(w1_1, w3_1, how='left', on='일시').drop(['기온_세종', '강수량_세종', '풍속_세종', '습도_세종', '미세먼지_속초'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "59TPjDT7sDj-"
   },
   "outputs": [],
   "source": [
    "# 2019날씨 결측값 대체\n",
    "cols = list(weather_2019.columns)[1:]\n",
    "for col in cols:\n",
    "  idx = weather_2019[weather_2019[col].isna()].index\n",
    "  for i in idx:\n",
    "    weather_2019.loc[i, col] = np.round(weather_2019.loc[i-3:i+3, col].mean(skipna=True), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "1U5IhSD1sDh-"
   },
   "outputs": [],
   "source": [
    "# 2020날시 결측값 대체\n",
    "cols = list(weather_2020.columns)[1:]\n",
    "for col in cols:\n",
    "  idx = weather_2020[weather_2020[col].isna()].index\n",
    "  for i in idx:\n",
    "    weather_2020.loc[i, col] = np.round(weather_2020.loc[i-3:i+3, col].mean(skipna=True), 1)\n",
    "for col in cols:\n",
    "  idx = weather_2020[weather_2020[col].isna()].index\n",
    "  for i in idx:\n",
    "    weather_2020.loc[i, col] = np.round(weather_2020.loc[i-3:i+3, col].mean(skipna=True), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "RaZDf7Hvr3i7"
   },
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_df, weather_2019, how='left', on='일시')\n",
    "test_df = pd.merge(test_df, weather_2020, how='left', on='일시')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "5XrAPN7EsXul"
   },
   "outputs": [],
   "source": [
    "temp_mean = train_df.iloc[:, range(19, 103, 4)].mean(axis=1)\n",
    "temp_median = train_df.iloc[:, range(19, 103, 4)].median(axis=1)\n",
    "temp_std = train_df.iloc[:, range(19, 103, 4)].std(axis=1)\n",
    "rain_mean = train_df.iloc[:, range(20, 104, 4)].mean(axis=1)\n",
    "rain_median = train_df.iloc[:, range(20, 104, 4)].median(axis=1)\n",
    "rain_std = train_df.iloc[:, range(20, 104, 4)].std(axis=1)\n",
    "wind_mean = train_df.iloc[:, range(21, 104, 4)].mean(axis=1)\n",
    "wind_median = train_df.iloc[:, range(21, 104, 4)].median(axis=1)\n",
    "wind_std = train_df.iloc[:, range(21, 104, 4)].std(axis=1)\n",
    "wet_mean = train_df.iloc[:, range(22, 104, 4)].mean(axis=1)\n",
    "wet_median = train_df.iloc[:, range(22, 104, 4)].median(axis=1)\n",
    "wet_std = train_df.iloc[:, range(22, 104, 4)].std(axis=1)\n",
    "mis_mean = train_df.iloc[:, range(103, 112)].mean(axis=1)\n",
    "mis_median = train_df.iloc[:, range(103, 112)].median(axis=1)\n",
    "mis_std = train_df.iloc[:, range(103, 112)].std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "RxnMA90zsXwy"
   },
   "outputs": [],
   "source": [
    "tc = list(train_df.columns[19:112])\n",
    "train_df.drop(tc, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "LwNUKns2tYar"
   },
   "outputs": [],
   "source": [
    "train_df['temp_mean'] = temp_mean\n",
    "train_df['temp_median'] = temp_median\n",
    "train_df['temp_std'] = temp_std\n",
    "train_df['rain_mean'] = rain_mean\n",
    "train_df['rain_median'] = rain_median\n",
    "train_df['rain_std'] = rain_std\n",
    "train_df['wind_mean'] = wind_mean\n",
    "train_df['wind_median'] = wind_median\n",
    "train_df['wind_std'] = wind_std\n",
    "train_df['wet_mean'] = wet_mean\n",
    "train_df['wet_median'] = wet_median\n",
    "train_df['wet_std'] = wet_std\n",
    "train_df['mis_mean'] = mis_mean\n",
    "train_df['mis_median'] = mis_median\n",
    "train_df['mis_std'] = mis_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "vRXojVNptYVU"
   },
   "outputs": [],
   "source": [
    "temp_mean = test_df.iloc[:, range(18, 102, 4)].mean(axis=1)\n",
    "temp_median = test_df.iloc[:, range(18, 102, 4)].median(axis=1)\n",
    "temp_std = test_df.iloc[:, range(18, 102, 4)].std(axis=1)\n",
    "rain_mean = test_df.iloc[:, range(19, 103, 4)].mean(axis=1)\n",
    "rain_median = test_df.iloc[:, range(19, 103, 4)].median(axis=1)\n",
    "rain_std = test_df.iloc[:, range(19, 103, 4)].std(axis=1)\n",
    "wind_mean = test_df.iloc[:, range(20, 103, 4)].mean(axis=1)\n",
    "wind_median = test_df.iloc[:, range(20, 103, 4)].median(axis=1)\n",
    "wind_std = test_df.iloc[:, range(20, 103, 4)].std(axis=1)\n",
    "wet_mean = test_df.iloc[:, range(21, 103, 4)].mean(axis=1)\n",
    "wet_median = test_df.iloc[:, range(21, 103, 4)].median(axis=1)\n",
    "wet_std = test_df.iloc[:, range(21, 103, 4)].std(axis=1)\n",
    "mis_mean = test_df.iloc[:, range(102, 111)].mean(axis=1)\n",
    "mis_median = test_df.iloc[:, range(102, 111)].median(axis=1)\n",
    "mis_std = test_df.iloc[:, range(102, 111)].std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "bd_xfl-YtYTe"
   },
   "outputs": [],
   "source": [
    "tc = list(test_df.columns[18:111])\n",
    "test_df.drop(tc, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ip_4qP5GsXj4"
   },
   "outputs": [],
   "source": [
    "test_df['temp_mean'] = temp_mean\n",
    "test_df['temp_median'] = temp_median\n",
    "test_df['temp_std'] = temp_std\n",
    "test_df['rain_mean'] = rain_mean\n",
    "test_df['rain_median'] = rain_median\n",
    "test_df['rain_std'] = rain_std\n",
    "test_df['wind_mean'] = wind_mean\n",
    "test_df['wind_median'] = wind_median\n",
    "test_df['wind_std'] = wind_std\n",
    "test_df['wet_mean'] = wet_mean\n",
    "test_df['wet_median'] = wet_median\n",
    "test_df['wet_std'] = wet_std\n",
    "test_df['mis_mean'] = mis_mean\n",
    "test_df['mis_median'] = mis_median\n",
    "test_df['mis_std'] = mis_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYNkppmUFcsJ"
   },
   "source": [
    "### (4) 프라임타임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAXnWgA--Zqo"
   },
   "source": [
    "#### (4)-3. 요일+상품군별 프라임타임 & 스윙타임\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCN8fj2PxtJj"
   },
   "source": [
    "특정 상품군, 요일 내 시간대별 매출액 평균을 구하여 상위 20%, 하위 20%에 해당하는 시간대들을 각각 primetime, swingtime으로 지정\n",
    "\n",
    "(취급액이 0인 상품들은 제외하여 계산하였음.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "id": "oMypfXEUyhla",
    "outputId": "8b36870d-ab2d-441e-98f4-e306a7303a02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "무형 0\n",
      "무형 1\n",
      "무형 2\n",
      "무형 3\n",
      "무형 4\n",
      "무형 5\n",
      "무형 6\n",
      "침구 5\n"
     ]
    }
   ],
   "source": [
    "primetime = pd.DataFrame(index=range(0,24), columns=[0,1,2,3,4,5,6])\n",
    "train_df['Primetime'] = 0\n",
    "train_df['Swingtime'] = 0\n",
    "\n",
    "for j in train_df.상품군.unique():\n",
    "  for i in range(0,7):\n",
    "    try:\n",
    "      pd.qcut(train_df[train_df.상품군==j][train_df.weekday==i][train_df.취급액!=0]['취급액'].groupby([train_df['hour']]).mean().round(), 5, [1,2,3,4,5])\n",
    "    except:\n",
    "      print(j, i)\n",
    "      if j=='침구':\n",
    "        train_df.loc[(train_df.상품군==j)&(train_df.weekday==i)&(train_df.취급액!=0), \"Primetime\"] = 1\n",
    "        test_df.loc[(train_df.상품군==j)&(train_df.weekday==i)&(train_df.취급액!=0), \"Primetime\"] = 1\n",
    "    else:\n",
    "      primetime[i] = pd.qcut(train_df[train_df.상품군==j][train_df.weekday==i][train_df.취급액!=0]['취급액'].groupby([train_df['hour']]).mean().round(), 5, [1,2,3,4,5])\n",
    "      train_df.loc[(train_df.상품군==j)&(train_df.weekday==i)&(train_df.취급액!=0), \"Primetime\"] = train_df[train_df.상품군==j][train_df.weekday==i]['hour'].map(lambda x: 1 if primetime.loc[x, i]==5 else 0)\n",
    "      train_df.loc[(train_df.상품군==j)&(train_df.weekday==i)&(train_df.취급액!=0), \"Swingtime\"] = train_df[train_df.상품군==j][train_df.weekday==i]['hour'].map(lambda x: 1 if primetime.loc[x, i]==1 else 0)\n",
    "\n",
    "      test_df.loc[(test_df.상품군==j)&(test_df.weekday==i)&(train_df.취급액!=0), \"Primetime\"] = test_df[test_df.상품군==j][test_df.weekday==i]['hour'].map(lambda x: 1 if primetime.loc[x, i]==5 else 0)\n",
    "      test_df.loc[(test_df.상품군==j)&(test_df.weekday==i)&(train_df.취급액!=0), \"Swingtime\"] = test_df[test_df.상품군==j][test_df.weekday==i]['hour'].map(lambda x: 1 if primetime.loc[x, i]==1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLeTttjDmPyh"
   },
   "source": [
    "### (5) 시청률 통계량"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "5iuULKV_mPyi"
   },
   "outputs": [],
   "source": [
    "rating_df = rating_df.iloc[:-1, :-1]\n",
    "new_df = rating_df.melt(id_vars=\"시간대\", var_name=\"date\", value_name=\"view\")\n",
    "new_df['방송일시'] = pd.to_datetime(new_df['시간대']+' '+new_df['date'])\n",
    "new_df = new_df[['방송일시','view']]\n",
    "new_df= new_df.dropna(axis=0)\n",
    "dff = new_df\n",
    "new_df = new_df.set_index('방송일시')\n",
    "new_df['view'] = new_df['view'].astype(float)\n",
    "dff['view'] = dff['view'].astype(float)\n",
    "jan_df = pd.DataFrame(index=range(0,24), columns=['weekday', 'hour', 'view_sum', 'view_mean', 'view_std'])\n",
    "suss =  pd.DataFrame(index=range(0), columns=['weekday', 'hour', 'view_sum', 'view_mean', 'view_std'])\n",
    "dff['year']= dff['방송일시'].dt.year\n",
    "dff['month']= dff['방송일시'].dt.month\n",
    "dff['day']= dff['방송일시'].dt.day\n",
    "dff['weekday']= dff['방송일시'].dt.weekday\n",
    "dff['weekofyear']= dff['방송일시'].dt.weekofyear\n",
    "dff['hour']= dff['방송일시'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "iyaK1oaamPym"
   },
   "outputs": [],
   "source": [
    "for k in range(0, 7):\n",
    "  #jan_df=pd.DataFrame(index=range(0,24), columns=['월정보','요일정보', '시정보','합계','평균','표준편차'])\n",
    "  j = 0\n",
    "  for i in range(0,24):\n",
    "    jan_df['weekday'][j] = k\n",
    "    jan_df['hour'][j] = i\n",
    "    jan_df['view_sum'][j] = dff[(dff['weekday']==k) & (dff['hour']==i)]['view'].sum()\n",
    "    jan_df['view_mean'][j]= dff[(dff['weekday']==k) & (dff['hour']==i)]['view'].mean()\n",
    "    jan_df['view_std'][j]= dff[(dff['weekday']==k) & (dff['hour']==i)]['view'].std()\n",
    "    j += 1\n",
    "  suss = suss.append(jan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "8_QymYLwmPyq"
   },
   "outputs": [],
   "source": [
    "suss['weekday'] = suss['weekday'].astype('int')\n",
    "suss['hour'] = suss['hour'].astype('int')\n",
    "suss['view_sum'] = suss['view_sum'].astype('float')\n",
    "suss['view_mean'] = suss['view_mean'].astype('float')\n",
    "suss['view_std'] = suss['view_std'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "AWqI7oJJmPyu"
   },
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_df, suss, on=['weekday', 'hour'], how='left')\n",
    "test_df = pd.merge(test_df, suss, on=['weekday', 'hour'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhG7mxLAGZz2"
   },
   "source": [
    "### (6) 판매단가 binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "sGOJeZThhpi9"
   },
   "outputs": [],
   "source": [
    "bins = [-1] + list(range(20000,100000,10000)) + list(range(100000,500000,50000)) + list(range(500000,1000000,100000)) + list(range(1000000,4000000,1000000)) +  [4000000, 8000000]  # (0-10000] : 취급액 0만 포함됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "G83jVhWlmAug"
   },
   "outputs": [],
   "source": [
    "train_df['판매단가bin'] = 0\n",
    "\n",
    "bins = [-1,0] + list(range(20000,100000,10000)) + list(range(100000,500000,50000)) + list(range(500000,1000000,100000)) + list(range(1000000,3000000,1000000)) +  [3000000, 8000000]  # (0-10000] : 취급액 0만 포함됨\n",
    "labels = list(range(0,26))\n",
    "train_df['판매단가bin'] = pd.cut(train_df['판매단가'], bins = bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "zAx4L0wznxES"
   },
   "outputs": [],
   "source": [
    "test_df['판매단가bin'] = 0\n",
    "\n",
    "bins = [-1,0] + list(range(20000,100000,10000)) + list(range(100000,500000,50000)) + list(range(500000,1000000,100000)) + list(range(1000000,3000000,1000000)) +  [3000000, 8000000]  # (0-10000] : 취급액 0만 포함됨\n",
    "labels = list(range(0,26))\n",
    "test_df['판매단가bin'] = pd.cut(test_df['판매단가'], bins = bins, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwOz7FTcuVF-"
   },
   "source": [
    "### (7) 방송순서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "mlsGy1XUuZSl"
   },
   "outputs": [],
   "source": [
    "train_df['방송순서'] = 1\n",
    "sang = train_df['상품코드'].unique()\n",
    "si = np.timedelta64(3600000000000,'ns')\n",
    "\n",
    "for s in sang:\n",
    "  ts = train_df[train_df['상품코드'] == s]\n",
    "  idx = ts.index\n",
    "  l1 = len(idx)\n",
    "  cnt = 1\n",
    "  for i in range(1, l1):\n",
    "    if (ts.loc[idx[i], '방송일시'] - ts.loc[idx[i-1], '방송일시']) <= si:\n",
    "      cnt += 1\n",
    "      train_df.loc[idx[i], '방송순서'] = cnt\n",
    "    else:\n",
    "      cnt = 1\n",
    "\n",
    "test_df['방송순서'] = 1\n",
    "sang = test_df['상품코드'].unique()\n",
    "\n",
    "for s in sang:\n",
    "  ts = test_df[test_df['상품코드'] == s]\n",
    "  idx = ts.index\n",
    "  l1 = len(idx)\n",
    "  cnt = 1\n",
    "  for i in range(1, l1):\n",
    "    if (ts.loc[idx[i], '방송일시'] - ts.loc[idx[i-1], '방송일시']) <= si:\n",
    "      cnt += 1\n",
    "      test_df.loc[idx[i], '방송순서'] = cnt\n",
    "    else:\n",
    "      cnt = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDfcqrKYuZwL"
   },
   "source": [
    "### (8) 실제노출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "JMLO0MRguUUt"
   },
   "outputs": [],
   "source": [
    "bang1 = train_df.groupby('방송일시').size().reset_index(name='동시방송상품')\n",
    "bang2 = test_df.groupby('방송일시').size().reset_index(name='동시방송상품')\n",
    "train_df = pd.merge(train_df, bang1, on='방송일시', how='left')\n",
    "test_df = pd.merge(test_df, bang2, on='방송일시', how='left')\n",
    "train_df['실제노출'] = train_df['노출(분)'] / train_df['동시방송상품']\n",
    "test_df['실제노출'] = test_df['노출(분)'] / test_df['동시방송상품']\n",
    "train_df.drop('동시방송상품', axis=1, inplace=True)\n",
    "test_df.drop('동시방송상품', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubThclY-GDcT"
   },
   "source": [
    "### (9) Brand Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "UlZhcSdhGHbu"
   },
   "outputs": [],
   "source": [
    "train_df['new_name'] = train_df['상품명'] #train_df['상품군'] + train_df['상품명'] \n",
    "test_df['new_name'] = test_df['상품명'] #test_df['상품군'] + test_df['상품명']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "OjzLjUZmGfdZ"
   },
   "outputs": [],
   "source": [
    "__all__ = [\"split_syllable_char\", \"split_syllables\",\n",
    "           \"join_jamos\", \"join_jamos_char\",\n",
    "           \"CHAR_INITIALS\", \"CHAR_MEDIALS\", \"CHAR_FINALS\"]\n",
    "\n",
    "import itertools\n",
    "\n",
    "INITIAL = 0x001\n",
    "MEDIAL = 0x010\n",
    "FINAL = 0x100\n",
    "CHAR_LISTS = {\n",
    "    INITIAL: list(map(chr, [\n",
    "        0x3131, 0x3132, 0x3134, 0x3137, 0x3138, 0x3139,\n",
    "        0x3141, 0x3142, 0x3143, 0x3145, 0x3146, 0x3147,\n",
    "        0x3148, 0x3149, 0x314a, 0x314b, 0x314c, 0x314d,\n",
    "        0x314e\n",
    "    ])),\n",
    "    MEDIAL: list(map(chr, [\n",
    "        0x314f, 0x3150, 0x3151, 0x3152, 0x3153, 0x3154,\n",
    "        0x3155, 0x3156, 0x3157, 0x3158, 0x3159, 0x315a,\n",
    "        0x315b, 0x315c, 0x315d, 0x315e, 0x315f, 0x3160,\n",
    "        0x3161, 0x3162, 0x3163\n",
    "    ])),\n",
    "    FINAL: list(map(chr, [\n",
    "        0x3131, 0x3132, 0x3133, 0x3134, 0x3135, 0x3136,\n",
    "        0x3137, 0x3139, 0x313a, 0x313b, 0x313c, 0x313d,\n",
    "        0x313e, 0x313f, 0x3140, 0x3141, 0x3142, 0x3144,\n",
    "        0x3145, 0x3146, 0x3147, 0x3148, 0x314a, 0x314b,\n",
    "        0x314c, 0x314d, 0x314e\n",
    "    ]))\n",
    "}\n",
    "CHAR_INITIALS = CHAR_LISTS[INITIAL]\n",
    "CHAR_MEDIALS = CHAR_LISTS[MEDIAL]\n",
    "CHAR_FINALS = CHAR_LISTS[FINAL]\n",
    "CHAR_SETS = {k: set(v) for k, v in CHAR_LISTS.items()}\n",
    "CHARSET = set(itertools.chain(*CHAR_SETS.values()))\n",
    "CHAR_INDICES = {k: {c: i for i, c in enumerate(v)}\n",
    "                for k, v in CHAR_LISTS.items()}\n",
    "\n",
    "\n",
    "def is_hangul_syllable(c):\n",
    "    return 0xac00 <= ord(c) <= 0xd7a3  # Hangul Syllables\n",
    "\n",
    "\n",
    "def is_hangul_jamo(c):\n",
    "    return 0x1100 <= ord(c) <= 0x11ff  # Hangul Jamo\n",
    "\n",
    "\n",
    "def is_hangul_compat_jamo(c):\n",
    "    return 0x3130 <= ord(c) <= 0x318f  # Hangul Compatibility Jamo\n",
    "\n",
    "\n",
    "def is_hangul_jamo_exta(c):\n",
    "    return 0xa960 <= ord(c) <= 0xa97f  # Hangul Jamo Extended-A\n",
    "\n",
    "\n",
    "def is_hangul_jamo_extb(c):\n",
    "    return 0xd7b0 <= ord(c) <= 0xd7ff  # Hangul Jamo Extended-B\n",
    "\n",
    "\n",
    "def is_hangul(c):\n",
    "    return (is_hangul_syllable(c) or\n",
    "            is_hangul_jamo(c) or\n",
    "            is_hangul_compat_jamo(c) or\n",
    "            is_hangul_jamo_exta(c) or\n",
    "            is_hangul_jamo_extb(c))\n",
    "\n",
    "\n",
    "def is_supported_hangul(c):\n",
    "    return is_hangul_syllable(c) or is_hangul_compat_jamo(c)\n",
    "\n",
    "\n",
    "def check_hangul(c, jamo_only=False):\n",
    "    if not ((jamo_only or is_hangul_compat_jamo(c)) or is_supported_hangul(c)):\n",
    "        raise ValueError(f\"'{c}' is not a supported hangul character. \"\n",
    "                         f\"'Hangul Syllables' (0xac00 ~ 0xd7a3) and \"\n",
    "                         f\"'Hangul Compatibility Jamos' (0x3130 ~ 0x318f) are \"\n",
    "                         f\"supported at the moment.\")\n",
    "\n",
    "\n",
    "def get_jamo_type(c):\n",
    "    check_hangul(c)\n",
    "    assert is_hangul_compat_jamo(c), f\"not a jamo: {ord(c):x}\"\n",
    "    return sum(t for t, s in CHAR_SETS.items() if c in s)\n",
    "\n",
    "\n",
    "def split_syllable_char(c):\n",
    "    \"\"\"\n",
    "    Splits a given korean syllable into its components. Each component is\n",
    "    represented by Unicode in 'Hangul Compatibility Jamo' range.\n",
    "    Arguments:\n",
    "        c: A Korean character.\n",
    "    Returns:\n",
    "        A triple (initial, medial, final) of Hangul Compatibility Jamos.\n",
    "        If no jamo corresponds to a position, `None` is returned there.\n",
    "    Example:\n",
    "        >>> split_syllable_char(\"안\")\n",
    "        (\"ㅇ\", \"ㅏ\", \"ㄴ\")\n",
    "        >>> split_syllable_char(\"고\")\n",
    "        (\"ㄱ\", \"ㅗ\", None)\n",
    "        >>> split_syllable_char(\"ㅗ\")\n",
    "        (None, \"ㅗ\", None)\n",
    "        >>> split_syllable_char(\"ㅇ\")\n",
    "        (\"ㅇ\", None, None)\n",
    "    \"\"\"\n",
    "    check_hangul(c)\n",
    "    if len(c) != 1:\n",
    "        raise ValueError(\"Input string must have exactly one character.\")\n",
    "\n",
    "    init, med, final = None, None, None\n",
    "    if is_hangul_syllable(c):\n",
    "        offset = ord(c) - 0xac00\n",
    "        x = (offset - offset % 28) // 28\n",
    "        init, med, final = x // 21, x % 21, offset % 28\n",
    "        if not final:\n",
    "            final = None\n",
    "        else:\n",
    "            final -= 1\n",
    "    else:\n",
    "        pos = get_jamo_type(c)\n",
    "        if pos & INITIAL == INITIAL:\n",
    "            pos = INITIAL\n",
    "        elif pos & MEDIAL == MEDIAL:\n",
    "            pos = MEDIAL\n",
    "        elif pos & FINAL == FINAL:\n",
    "            pos = FINAL\n",
    "        idx = CHAR_INDICES[pos][c]\n",
    "        if pos == INITIAL:\n",
    "            init = idx\n",
    "        elif pos == MEDIAL:\n",
    "            med = idx\n",
    "        else:\n",
    "            final = idx\n",
    "    return tuple(CHAR_LISTS[pos][idx] if idx is not None else None\n",
    "                 for pos, idx in\n",
    "                 zip([INITIAL, MEDIAL, FINAL], [init, med, final]))\n",
    "\n",
    "\n",
    "def split_syllables(s, ignore_err=True, pad=None):\n",
    "    \"\"\"\n",
    "    Performs syllable-split on a string.\n",
    "    Arguments:\n",
    "        s (str): A string (possibly mixed with non-Hangul characters).\n",
    "        ignore_err (bool): If set False, it ensures that all characters in\n",
    "            the string are Hangul-splittable and throws a ValueError otherwise.\n",
    "            (default: True)\n",
    "        pad (str): Pad empty jamo positions (initial, medial, or final) with\n",
    "            `pad` character. This is useful for cases where fixed-length\n",
    "            strings are needed. (default: None)\n",
    "    Returns:\n",
    "        Hangul-split string\n",
    "    Example:\n",
    "        >>> split_syllables(\"안녕하세요\")\n",
    "        \"ㅇㅏㄴㄴㅕㅇㅎㅏㅅㅔㅇㅛ\"\n",
    "        >>> split_syllables(\"안녕하세요~~\", ignore_err=False)\n",
    "        ValueError: encountered an unsupported character: ~ (0x7e)\n",
    "        >>> split_syllables(\"안녕하세요ㅛ\", pad=\"x\")\n",
    "        'ㅇㅏㄴㄴㅕㅇㅎㅏxㅅㅔxㅇㅛxxㅛx'\n",
    "    \"\"\"\n",
    "\n",
    "    def try_split(c):\n",
    "        try:\n",
    "            return split_syllable_char(c)\n",
    "        except ValueError:\n",
    "            if ignore_err:\n",
    "                return (c,)\n",
    "            raise ValueError(f\"encountered an unsupported character: \"\n",
    "                             f\"{c} (0x{ord(c):x})\")\n",
    "\n",
    "    s = map(try_split, s)\n",
    "    if pad is not None:\n",
    "        tuples = map(lambda x: tuple(pad if y is None else y for y in x), s)\n",
    "    else:\n",
    "        tuples = map(lambda x: filter(None, x), s)\n",
    "    return \"\".join(itertools.chain(*tuples))\n",
    "\n",
    "\n",
    "def join_jamos_char(init, med, final=None):\n",
    "    \"\"\"\n",
    "    Combines jamos into a single syllable.\n",
    "    Arguments:\n",
    "        init (str): Initial jao.\n",
    "        med (str): Medial jamo.\n",
    "        final (str): Final jamo. If not supplied, the final syllable is made\n",
    "            without the final. (default: None)\n",
    "    Returns:\n",
    "        A Korean syllable.\n",
    "    \"\"\"\n",
    "    chars = (init, med, final)\n",
    "    for c in filter(None, chars):\n",
    "        check_hangul(c, jamo_only=True)\n",
    "\n",
    "    idx = tuple(CHAR_INDICES[pos][c] if c is not None else c\n",
    "                for pos, c in zip((INITIAL, MEDIAL, FINAL), chars))\n",
    "    init_idx, med_idx, final_idx = idx\n",
    "    # final index must be shifted once as\n",
    "    # final index with 0 points to syllables without final\n",
    "    final_idx = 0 if final_idx is None else final_idx + 1\n",
    "    return chr(0xac00 + 28 * 21 * init_idx + 28 * med_idx + final_idx)\n",
    "\n",
    "\n",
    "def join_jamos(s, ignore_err=True):\n",
    "    \"\"\"\n",
    "    Combines a sequence of jamos to produce a sequence of syllables.\n",
    "    Arguments:\n",
    "        s (str): A string (possible mixed with non-jamo characters).\n",
    "        ignore_err (bool): If set False, it will ensure that all characters\n",
    "            will be consumed for the making of syllables. It will throw a\n",
    "            ValueError when it fails to do so. (default: True)\n",
    "    Returns:\n",
    "        A string\n",
    "    Example:\n",
    "        >>> join_jamos(\"ㅇㅏㄴㄴㅕㅇㅎㅏㅅㅔㅇㅛ\")\n",
    "        \"안녕하세요\"\n",
    "        >>> join_jamos(\"ㅇㅏㄴㄴㄴㅕㅇㅎㅏㅅㅔㅇㅛ\")\n",
    "        \"안ㄴ녕하세요\"\n",
    "        >>> join_jamos()\n",
    "    \"\"\"\n",
    "    last_t = 0\n",
    "    queue = []\n",
    "    new_string = \"\"\n",
    "\n",
    "    def flush(n=0):\n",
    "        new_queue = []\n",
    "        while len(queue) > n:\n",
    "            new_queue.append(queue.pop())\n",
    "        if len(new_queue) == 1:\n",
    "            if not ignore_err:\n",
    "                raise ValueError(f\"invalid jamo character: {new_queue[0]}\")\n",
    "            result = new_queue[0]\n",
    "        elif len(new_queue) >= 2:\n",
    "            try:\n",
    "                result = join_jamos_char(*new_queue)\n",
    "            except (ValueError, KeyError):\n",
    "                # Invalid jamo combination\n",
    "                if not ignore_err:\n",
    "                    raise ValueError(f\"invalid jamo characters: {new_queue}\")\n",
    "                result = \"\".join(new_queue)\n",
    "        else:\n",
    "            result = None\n",
    "        return result\n",
    "\n",
    "    for c in s:\n",
    "        if c not in CHARSET:\n",
    "            if queue:\n",
    "                new_c = flush() + c\n",
    "            else:\n",
    "                new_c = c\n",
    "            last_t = 0\n",
    "        else:\n",
    "            t = get_jamo_type(c)\n",
    "            new_c = None\n",
    "            if t & FINAL == FINAL:\n",
    "                if not (last_t == MEDIAL):\n",
    "                    new_c = flush()\n",
    "            elif t == INITIAL:\n",
    "                new_c = flush()\n",
    "            elif t == MEDIAL:\n",
    "                if last_t & INITIAL == INITIAL:\n",
    "                    new_c = flush(1)\n",
    "                else:\n",
    "                    new_c = flush()\n",
    "            last_t = t\n",
    "            queue.insert(0, c)\n",
    "        if new_c:\n",
    "            new_string += new_c\n",
    "    if queue:\n",
    "        new_string += flush()\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "L5jOaN0XGuFV"
   },
   "outputs": [],
   "source": [
    "train_df['new_name'] = train_df['new_name'].apply(split_syllables)\n",
    "test_df['new_name'] = test_df['new_name'].apply(split_syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "6PklrpfnGwvr"
   },
   "outputs": [],
   "source": [
    "words = train_df['new_name'].unique()\n",
    "words = np.asarray(words)\n",
    "lev_similarity = -1*np.array([[dist.levenshtein(w1,w2) for w1 in words] for w2 in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "bnbEP9xUG9zy",
    "outputId": "9abe6db9-b07b-4293-af4f-cf7c1dd2702c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1770, 1770)"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lev_similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "yi04v7wQHFJ6"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "병합군집\n",
    "'''\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "agg = AgglomerativeClustering(n_clusters=len(train_df['마더코드'].unique())-145, affinity='precomputed',\n",
    "                              linkage='complete')\n",
    "\n",
    "u = agg.fit_predict(lev_similarity*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "6PdXtDDSHL1p",
    "outputId": "037326e0-cffd-44ac-c55d-2bb619e36293"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_name</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ㅌㅔㅇㅣㅌㅡ ㄴㅏㅁㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ㅌㅔㅇㅣㅌㅡ ㅇㅕㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ㅇㅗㅁㅗㄸㅔ ㄹㅔㅇㅣㅅㅡ ㅍㅏㅇㅜㄴㄷㅔㅇㅣㅅㅕㄴ ㅂㅡㄹㅏ</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CERINI by PAT ㄴㅏㅁㅅㅓㅇ ㅅㅗㅍㅡㅌㅡ ㄱㅣㅁㅗ ㄹㅣㄹㄹㅔㄱㅅㅡㅍㅐㄴㅊㅡ</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ㅂㅗㅋㅗ ㄹㅣㅂㅓㅅㅣㅂㅡㄹ ㅁㅜㅅㅡㅌㅏㅇ</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         new_name  clusters\n",
       "0                    ㅌㅔㅇㅣㅌㅡ ㄴㅏㅁㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ        25\n",
       "1                     ㅌㅔㅇㅣㅌㅡ ㅇㅕㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ        25\n",
       "2                 ㅇㅗㅁㅗㄸㅔ ㄹㅔㅇㅣㅅㅡ ㅍㅏㅇㅜㄴㄷㅔㅇㅣㅅㅕㄴ ㅂㅡㄹㅏ       122\n",
       "3  CERINI by PAT ㄴㅏㅁㅅㅓㅇ ㅅㅗㅍㅡㅌㅡ ㄱㅣㅁㅗ ㄹㅣㄹㄹㅔㄱㅅㅡㅍㅐㄴㅊㅡ        47\n",
       "4                          ㅂㅗㅋㅗ ㄹㅣㅂㅓㅅㅣㅂㅡㄹ ㅁㅜㅅㅡㅌㅏㅇ         9"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_cluster=pd.DataFrame({'new_name':words,\n",
    "                           'clusters':u})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mTrLoLP_HMvR",
    "outputId": "c7c35483-4e28-49b4-acb9-5b5673edfbc8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>방송일시</th>\n",
       "      <th>노출(분)</th>\n",
       "      <th>마더코드</th>\n",
       "      <th>상품코드</th>\n",
       "      <th>상품명</th>\n",
       "      <th>상품군</th>\n",
       "      <th>판매단가</th>\n",
       "      <th>취급액</th>\n",
       "      <th>주문량</th>\n",
       "      <th>일시</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>business_day</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>temp_median</th>\n",
       "      <th>temp_std</th>\n",
       "      <th>rain_mean</th>\n",
       "      <th>rain_median</th>\n",
       "      <th>rain_std</th>\n",
       "      <th>wind_mean</th>\n",
       "      <th>wind_median</th>\n",
       "      <th>wind_std</th>\n",
       "      <th>wet_mean</th>\n",
       "      <th>wet_median</th>\n",
       "      <th>wet_std</th>\n",
       "      <th>mis_mean</th>\n",
       "      <th>mis_median</th>\n",
       "      <th>mis_std</th>\n",
       "      <th>Primetime</th>\n",
       "      <th>Swingtime</th>\n",
       "      <th>view_sum</th>\n",
       "      <th>view_mean</th>\n",
       "      <th>view_std</th>\n",
       "      <th>판매단가bin</th>\n",
       "      <th>방송순서</th>\n",
       "      <th>실제노출</th>\n",
       "      <th>new_name</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100346</td>\n",
       "      <td>201072</td>\n",
       "      <td>테이트 남성 셀린니트3종</td>\n",
       "      <td>의류</td>\n",
       "      <td>39900</td>\n",
       "      <td>2099000.0</td>\n",
       "      <td>52.606516</td>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.309524</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>4.773668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.554778</td>\n",
       "      <td>63.380952</td>\n",
       "      <td>62.0</td>\n",
       "      <td>15.078051</td>\n",
       "      <td>37.888889</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.594008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.633</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ㅌㅔㅇㅣㅌㅡ ㄴㅏㅁㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100346</td>\n",
       "      <td>201079</td>\n",
       "      <td>테이트 여성 셀린니트3종</td>\n",
       "      <td>의류</td>\n",
       "      <td>39900</td>\n",
       "      <td>4371000.0</td>\n",
       "      <td>109.548872</td>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.309524</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>4.773668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.554778</td>\n",
       "      <td>63.380952</td>\n",
       "      <td>62.0</td>\n",
       "      <td>15.078051</td>\n",
       "      <td>37.888889</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.594008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.633</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ㅌㅔㅇㅣㅌㅡ ㅇㅕㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 06:20:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100346</td>\n",
       "      <td>201072</td>\n",
       "      <td>테이트 남성 셀린니트3종</td>\n",
       "      <td>의류</td>\n",
       "      <td>39900</td>\n",
       "      <td>3262000.0</td>\n",
       "      <td>81.754386</td>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.309524</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>4.773668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.554778</td>\n",
       "      <td>63.380952</td>\n",
       "      <td>62.0</td>\n",
       "      <td>15.078051</td>\n",
       "      <td>37.888889</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.594008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.633</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ㅌㅔㅇㅣㅌㅡ ㄴㅏㅁㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 06:20:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100346</td>\n",
       "      <td>201079</td>\n",
       "      <td>테이트 여성 셀린니트3종</td>\n",
       "      <td>의류</td>\n",
       "      <td>39900</td>\n",
       "      <td>6955000.0</td>\n",
       "      <td>174.310777</td>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.309524</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>4.773668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.554778</td>\n",
       "      <td>63.380952</td>\n",
       "      <td>62.0</td>\n",
       "      <td>15.078051</td>\n",
       "      <td>37.888889</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.594008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.633</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ㅌㅔㅇㅣㅌㅡ ㅇㅕㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 06:40:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100346</td>\n",
       "      <td>201072</td>\n",
       "      <td>테이트 남성 셀린니트3종</td>\n",
       "      <td>의류</td>\n",
       "      <td>39900</td>\n",
       "      <td>6672000.0</td>\n",
       "      <td>167.218045</td>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.309524</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>4.773668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.554778</td>\n",
       "      <td>63.380952</td>\n",
       "      <td>62.0</td>\n",
       "      <td>15.078051</td>\n",
       "      <td>37.888889</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.594008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.633</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ㅌㅔㅇㅣㅌㅡ ㄴㅏㅁㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 방송일시  노출(분)  ...                      new_name  clusters\n",
       "0 2019-01-01 06:00:00   20.0  ...  ㅌㅔㅇㅣㅌㅡ ㄴㅏㅁㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ        25\n",
       "1 2019-01-01 06:00:00   20.0  ...   ㅌㅔㅇㅣㅌㅡ ㅇㅕㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ        25\n",
       "2 2019-01-01 06:20:00   20.0  ...  ㅌㅔㅇㅣㅌㅡ ㄴㅏㅁㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ        25\n",
       "3 2019-01-01 06:20:00   20.0  ...   ㅌㅔㅇㅣㅌㅡ ㅇㅕㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ        25\n",
       "4 2019-01-01 06:40:00   20.0  ...  ㅌㅔㅇㅣㅌㅡ ㄴㅏㅁㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ        25\n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.merge(name_cluster, on='new_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "L5mZvZACHVJN"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "test data에 적용\n",
    "'''\n",
    "\n",
    "def find_min_c(test_name):\n",
    "  min_dict= {}\n",
    "  for c in train_df['clusters'].unique():\n",
    "    name_list = train_df.loc[train_df['clusters']==c,'new_name'].unique()\n",
    "    score_list = []\n",
    "    for name in name_list:\n",
    "      score_list.append(dist.levenshtein(name,test_name))\n",
    "    \n",
    "    min_dict[c] = sum(score_list)/len(score_list)\n",
    "    temp = min(min_dict.values()) \n",
    "    res = [key for key in min_dict if min_dict[key] == temp]\n",
    "  \n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "H5KDx7XlHyw1"
   },
   "outputs": [],
   "source": [
    "test_df['cluster_dict']=test_df['new_name'].apply(find_min_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "aUIyHNtAH0aJ"
   },
   "outputs": [],
   "source": [
    "test_df['cluster_dict'] = test_df['cluster_dict'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "v-ViyH-zH2Mu"
   },
   "outputs": [],
   "source": [
    "test_df['cc'] = '0'\n",
    "idx = 0\n",
    "for c in test_df['cluster_dict']:\n",
    "  if ',' in str(c):\n",
    "    c = c.replace(' ', '')[1:-1]\n",
    "    test_df['cc'].iloc[idx] = c\n",
    "    idx += 1\n",
    "    continue\n",
    "  else:\n",
    "    c = str(c)[1:-1]\n",
    "    test_df['cc'].iloc[idx] = str(c)\n",
    "    idx += 1\n",
    "    continue\n",
    "\n",
    "test_df['new_clusters'] = 0\n",
    "for i, t in test_df.iterrows():\n",
    "  if ',' in t['cc']:\n",
    "    l1 = []\n",
    "    tl = t['cc'].split(',')\n",
    "    for c in tl:\n",
    "      c = int(c)\n",
    "      sang = train_df[train_df['clusters'] == c]['상품군'].unique()\n",
    "      if t['상품군'] in sang:\n",
    "        l1.append(c)\n",
    "    l1 = list(set(l1))\n",
    "    cls = 0\n",
    "    if len(l1) > 1:\n",
    "      cls = l1[0]\n",
    "      k = train_df[train_df['clusters'] == cls]['new_name'].nunique()\n",
    "      for c in l1[1:]:\n",
    "        if k < train_df[train_df['clusters'] == c]['new_name'].nunique():\n",
    "          k = train_df[train_df['clusters'] == c]['new_name'].nunique()\n",
    "          cls = c\n",
    "      test_df.loc[i, 'new_clusters'] = cls\n",
    "    elif len(l1) == 0:\n",
    "      cls = int(tl[0])\n",
    "      k = train_df[train_df['clusters'] == cls]['new_name'].nunique()\n",
    "      for c in tl[1:]:\n",
    "        c = int(c)\n",
    "        if k < train_df[train_df['clusters'] == c]['new_name'].nunique():\n",
    "          k = train_df[train_df['clusters'] == c]['new_name'].nunique()\n",
    "          cls = c\n",
    "      test_df.loc[i, 'new_clusters'] = cls\n",
    "    else:\n",
    "      cls = l1[0]\n",
    "      test_df.loc[i, 'new_clusters'] = cls\n",
    "  else:\n",
    "    test_df.loc[i, 'new_clusters'] = int(t['cc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jzQMxSxKICJP",
    "outputId": "a0a0ee91-1e6e-4851-fe07-38e72768943f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>방송일시</th>\n",
       "      <th>노출(분)</th>\n",
       "      <th>마더코드</th>\n",
       "      <th>상품코드</th>\n",
       "      <th>상품명</th>\n",
       "      <th>상품군</th>\n",
       "      <th>판매단가</th>\n",
       "      <th>취급액</th>\n",
       "      <th>주문량</th>\n",
       "      <th>일시</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>business_day</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>temp_median</th>\n",
       "      <th>temp_std</th>\n",
       "      <th>rain_mean</th>\n",
       "      <th>rain_median</th>\n",
       "      <th>rain_std</th>\n",
       "      <th>wind_mean</th>\n",
       "      <th>wind_median</th>\n",
       "      <th>wind_std</th>\n",
       "      <th>wet_mean</th>\n",
       "      <th>wet_median</th>\n",
       "      <th>wet_std</th>\n",
       "      <th>mis_mean</th>\n",
       "      <th>mis_median</th>\n",
       "      <th>mis_std</th>\n",
       "      <th>Primetime</th>\n",
       "      <th>Swingtime</th>\n",
       "      <th>view_sum</th>\n",
       "      <th>view_mean</th>\n",
       "      <th>view_std</th>\n",
       "      <th>판매단가bin</th>\n",
       "      <th>방송순서</th>\n",
       "      <th>실제노출</th>\n",
       "      <th>new_name</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100346</td>\n",
       "      <td>201072</td>\n",
       "      <td>테이트 남성 셀린니트3종</td>\n",
       "      <td>의류</td>\n",
       "      <td>39900</td>\n",
       "      <td>2099000.0</td>\n",
       "      <td>52.606516</td>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.309524</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>4.773668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.554778</td>\n",
       "      <td>63.380952</td>\n",
       "      <td>62.0</td>\n",
       "      <td>15.078051</td>\n",
       "      <td>37.888889</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.594008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.633</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ㅌㅔㅇㅣㅌㅡ ㄴㅏㅁㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100346</td>\n",
       "      <td>201079</td>\n",
       "      <td>테이트 여성 셀린니트3종</td>\n",
       "      <td>의류</td>\n",
       "      <td>39900</td>\n",
       "      <td>4371000.0</td>\n",
       "      <td>109.548872</td>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.309524</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>4.773668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.554778</td>\n",
       "      <td>63.380952</td>\n",
       "      <td>62.0</td>\n",
       "      <td>15.078051</td>\n",
       "      <td>37.888889</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.594008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.633</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ㅌㅔㅇㅣㅌㅡ ㅇㅕㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 06:20:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100346</td>\n",
       "      <td>201072</td>\n",
       "      <td>테이트 남성 셀린니트3종</td>\n",
       "      <td>의류</td>\n",
       "      <td>39900</td>\n",
       "      <td>3262000.0</td>\n",
       "      <td>81.754386</td>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.309524</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>4.773668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.554778</td>\n",
       "      <td>63.380952</td>\n",
       "      <td>62.0</td>\n",
       "      <td>15.078051</td>\n",
       "      <td>37.888889</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.594008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.633</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ㅌㅔㅇㅣㅌㅡ ㄴㅏㅁㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 06:20:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100346</td>\n",
       "      <td>201079</td>\n",
       "      <td>테이트 여성 셀린니트3종</td>\n",
       "      <td>의류</td>\n",
       "      <td>39900</td>\n",
       "      <td>6955000.0</td>\n",
       "      <td>174.310777</td>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.309524</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>4.773668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.554778</td>\n",
       "      <td>63.380952</td>\n",
       "      <td>62.0</td>\n",
       "      <td>15.078051</td>\n",
       "      <td>37.888889</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.594008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.633</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ㅌㅔㅇㅣㅌㅡ ㅇㅕㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 06:40:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100346</td>\n",
       "      <td>201072</td>\n",
       "      <td>테이트 남성 셀린니트3종</td>\n",
       "      <td>의류</td>\n",
       "      <td>39900</td>\n",
       "      <td>6672000.0</td>\n",
       "      <td>167.218045</td>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.309524</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>4.773668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.554778</td>\n",
       "      <td>63.380952</td>\n",
       "      <td>62.0</td>\n",
       "      <td>15.078051</td>\n",
       "      <td>37.888889</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.594008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.633</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ㅌㅔㅇㅣㅌㅡ ㄴㅏㅁㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 방송일시  노출(분)  ...                      new_name  clusters\n",
       "0 2019-01-01 06:00:00   20.0  ...  ㅌㅔㅇㅣㅌㅡ ㄴㅏㅁㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ        25\n",
       "1 2019-01-01 06:00:00   20.0  ...   ㅌㅔㅇㅣㅌㅡ ㅇㅕㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ        25\n",
       "2 2019-01-01 06:20:00   20.0  ...  ㅌㅔㅇㅣㅌㅡ ㄴㅏㅁㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ        25\n",
       "3 2019-01-01 06:20:00   20.0  ...   ㅌㅔㅇㅣㅌㅡ ㅇㅕㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ        25\n",
       "4 2019-01-01 06:40:00   20.0  ...  ㅌㅔㅇㅣㅌㅡ ㄴㅏㅁㅅㅓㅇ ㅅㅔㄹㄹㅣㄴㄴㅣㅌㅡ3ㅈㅗㅇ        25\n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VH2iO0XyIDuS",
    "outputId": "0b08bd2c-f9b6-4910-efc2-56a968fe40a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>방송일시</th>\n",
       "      <th>노출(분)</th>\n",
       "      <th>마더코드</th>\n",
       "      <th>상품코드</th>\n",
       "      <th>상품명</th>\n",
       "      <th>상품군</th>\n",
       "      <th>판매단가</th>\n",
       "      <th>취급액</th>\n",
       "      <th>일시</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>business_day</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>temp_median</th>\n",
       "      <th>temp_std</th>\n",
       "      <th>rain_mean</th>\n",
       "      <th>rain_median</th>\n",
       "      <th>rain_std</th>\n",
       "      <th>wind_mean</th>\n",
       "      <th>wind_median</th>\n",
       "      <th>wind_std</th>\n",
       "      <th>wet_mean</th>\n",
       "      <th>wet_median</th>\n",
       "      <th>wet_std</th>\n",
       "      <th>mis_mean</th>\n",
       "      <th>mis_median</th>\n",
       "      <th>mis_std</th>\n",
       "      <th>Primetime</th>\n",
       "      <th>Swingtime</th>\n",
       "      <th>view_sum</th>\n",
       "      <th>view_mean</th>\n",
       "      <th>view_std</th>\n",
       "      <th>판매단가bin</th>\n",
       "      <th>방송순서</th>\n",
       "      <th>실제노출</th>\n",
       "      <th>new_name</th>\n",
       "      <th>cluster_dict</th>\n",
       "      <th>cc</th>\n",
       "      <th>new_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-01 06:20:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100650</td>\n",
       "      <td>201971</td>\n",
       "      <td>잭필드 남성  반팔셔츠 4종</td>\n",
       "      <td>의류</td>\n",
       "      <td>59800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-01 06:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>17.8</td>\n",
       "      <td>1.514596</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040237</td>\n",
       "      <td>1.690476</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.121118</td>\n",
       "      <td>88.714286</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10.335100</td>\n",
       "      <td>20.088889</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.827294</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.868</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>ㅈㅐㄱㅍㅣㄹㄷㅡ ㄴㅏㅁㅅㅓㅇ  ㅂㅏㄴㅍㅏㄹㅅㅕㅊㅡ 4ㅈㅗㅇ</td>\n",
       "      <td>[15]</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-01 06:40:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100650</td>\n",
       "      <td>201971</td>\n",
       "      <td>잭필드 남성  반팔셔츠 4종</td>\n",
       "      <td>의류</td>\n",
       "      <td>59800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-01 06:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>17.8</td>\n",
       "      <td>1.514596</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040237</td>\n",
       "      <td>1.690476</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.121118</td>\n",
       "      <td>88.714286</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10.335100</td>\n",
       "      <td>20.088889</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.827294</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.868</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>ㅈㅐㄱㅍㅣㄹㄷㅡ ㄴㅏㅁㅅㅓㅇ  ㅂㅏㄴㅍㅏㄹㅅㅕㅊㅡ 4ㅈㅗㅇ</td>\n",
       "      <td>[15]</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-01 07:00:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100650</td>\n",
       "      <td>201971</td>\n",
       "      <td>잭필드 남성  반팔셔츠 4종</td>\n",
       "      <td>의류</td>\n",
       "      <td>59800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-01 07:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.714286</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1.514030</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021822</td>\n",
       "      <td>1.823810</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.279807</td>\n",
       "      <td>85.809524</td>\n",
       "      <td>87.0</td>\n",
       "      <td>10.342239</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.535654</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.379</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.009230</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>ㅈㅐㄱㅍㅣㄹㄷㅡ ㄴㅏㅁㅅㅓㅇ  ㅂㅏㄴㅍㅏㄹㅅㅕㅊㅡ 4ㅈㅗㅇ</td>\n",
       "      <td>[15]</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-01 07:20:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100445</td>\n",
       "      <td>202278</td>\n",
       "      <td>쿠미투니카 쿨 레이시 란쥬쉐이퍼&amp;팬티</td>\n",
       "      <td>속옷</td>\n",
       "      <td>69900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-01 07:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.714286</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1.514030</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021822</td>\n",
       "      <td>1.823810</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.279807</td>\n",
       "      <td>85.809524</td>\n",
       "      <td>87.0</td>\n",
       "      <td>10.342239</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.535654</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.379</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.009230</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>ㅋㅜㅁㅣㅌㅜㄴㅣㅋㅏ ㅋㅜㄹ ㄹㅔㅇㅣㅅㅣ ㄹㅏㄴㅈㅠㅅㅞㅇㅣㅍㅓ&amp;ㅍㅐㄴㅌㅣ</td>\n",
       "      <td>[38]</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-01 07:40:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100445</td>\n",
       "      <td>202278</td>\n",
       "      <td>쿠미투니카 쿨 레이시 란쥬쉐이퍼&amp;팬티</td>\n",
       "      <td>속옷</td>\n",
       "      <td>69900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-01 07:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.714286</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1.514030</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021822</td>\n",
       "      <td>1.823810</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.279807</td>\n",
       "      <td>85.809524</td>\n",
       "      <td>87.0</td>\n",
       "      <td>10.342239</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.535654</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.379</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.009230</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>ㅋㅜㅁㅣㅌㅜㄴㅣㅋㅏ ㅋㅜㄹ ㄹㅔㅇㅣㅅㅣ ㄹㅏㄴㅈㅠㅅㅞㅇㅣㅍㅓ&amp;ㅍㅐㄴㅌㅣ</td>\n",
       "      <td>[38]</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 방송일시  노출(분)    마더코드  ...  cluster_dict  cc new_clusters\n",
       "0 2020-06-01 06:20:00   20.0  100650  ...          [15]  15           15\n",
       "1 2020-06-01 06:40:00   20.0  100650  ...          [15]  15           15\n",
       "2 2020-06-01 07:00:00   20.0  100650  ...          [15]  15           15\n",
       "3 2020-06-01 07:20:00   20.0  100445  ...          [38]  38           38\n",
       "4 2020-06-01 07:40:00   20.0  100445  ...          [38]  38           38\n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "234FLiZSIm-V"
   },
   "source": [
    "### (10) 상품명 중분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "sTviquyEIp1P"
   },
   "outputs": [],
   "source": [
    "under_wear=['코튼','언더탑','레이스','웨어','브라','팬티', '드로즈', '란쥬', '풍기인견','트렁크', '심리스', '런닝','언더셔츠', '남성','여성','레깅스', '내의','원피스','치마','홈웨어','주니어', '에센셜','티셔츠','스포츠','숏츠','쇼츠', '드레스']\n",
    "kichen=['지퍼백','다지기','중탕기','후레쉬','에어프라이어','커피머신','진공포장기','키친툴','팬','홈세트','제조기','멀티쿡','디너' ,'전기밥솥', '그릴', '압력밥솥', '냄비', '프라이팬', '용기', '텀블러', '가스레인지', '후라이팬', '블렌더', '오븐', '도마', '식기', '건조대', '가스레인지', '행주', '메이커', '싱크', '인덕션레인지', '전자레인지', '수세미', '믹서기', '티슈', '선반', '티포트', '소쿠리', '글라스', '건조기', '맷돌', '통구이', '바비큐', '착즙기', '곰팡이', '믹서', '가마솥', '분쇄', '테이블', '퀵스퀴저', '전골', '식기세척기', '인덕션', '보온병']\n",
    "wear=['기모','윈드','앙상블','풀코디','썸머','웨어','남성','여성','팬츠','티셔츠','코트','패딩','니트','데님','수트','밍크','자켓','베스트','재킷','터틀넥','블라우스','아웃도어','점퍼','컬렉션','구스','아동','골프','맨투맨','무스탕','스웨터','트렌치코트','셔츠','풍기인견','린넨','트레이닝','원피스','가디건','정장','벨트']\n",
    "food=['다시팩','사과','탕요일','김','매생이','쌀','떡','전복','갈치','갑오징어','숙성','홍어','갈비탕','꼬막','고등어', '꽃게','문어', '곰탕', '새우', '구이', '통오징어', '시래기', '갓김치', '포기', '김치', '햅쌀', '황태', '호빵', '양념', '안심', '벌꿀', '돼지', '동태', '소갈비', '살구', '갈비', '쥐포', '곡물', '생선', '광어', '삼계탕', '두유', '소한', '낙지', '양념장', '연포탕', '육수', '참조기', '머루', '야채', '대구', '매운탕', '순대', '곱창', '전골', '볶음', '메주', '한라봉', '천혜향', '갈비살', '옥수수', '옥돔', '오리', '들깨', '오렌지', '재첩국', '국밥', '쇠고기', '장조림', '부각', '찰보리', '식혜', '총각김치', '곤드', '물밥', '가자미', '그릴', '아구', '양태', '소스', '곱창전골', '간장', '전복장', '미리', '바다장어', '쉐이커통', '해물', '철판', '꼬리곰탕', '유기농', '매실', '능이', '누룽지', '병어', '열무김치', '마늘', '양파', '말랭이', '백김치', '녹용', '도가니탕', '한우', '콩국수', '배추김치', '닭발', '고춧가루', '치마', '영양', '강정', '칼슘', '호두', '아몬드', '다리', '두부', '수산물', '아카시아', '야생화', '오이소박이', '젓갈', '샤인', '머스켓', '삽겹', '도라지', '산돌', '배즙', '맛밤', '양갱', '대장', '굴비', '메기', '홍어회', '새꼬막', '치킨', '스테이크', '골뱅이', '감자탕', '참굴', '고구마', '랍스터', '점보', '크래커', '낙곱새']\n",
    "care=['펌','세럼','선','쿠션','롤','스틱','기초','남성','크림','립스틱','샴푸','콜라겐','트먼트', '클렌져','팩트','헤어','에센스','마스크','오일','클렌징','패드', '아이','케어','스프레이','셀프','퍼머','아이크','선크림','네일','탈모', '틴트','마스카라','아이라이너','리프트','브러쉬','퀵래쉬','속눈썹','릴렉싱', '파운데이션','샤워']\n",
    "family=[ 'TV','HD','UHD','에어컨','냉장고','건조기','공기청정기','노트북', '청소기','스탠드','도어','걸이','세탁기','초특','미니', '무선','김치냉장고','스타일','관리','캐리어','복합기','스피커','휴대', '청기','노크','선풍기','터보']\n",
    "life=['클리너','베이직','예초기','도어락','바리캉','스틱','디퓨저','조사기','샤워기','의자','플래티늄','매트','카페트','벽지','비데','마스크','매트리스','청소기', '안마','물걸레','패치','히터','빙박스','이볼브','매트릭스','가구', '걸이','공구','행거','마사지','블루투스','전등','턴테이블','메모리', '스티커','기기','방역','빨래','스쿼트','머신','롤링', '싱크대','배터리','면도기','이어폰','블랙박스','오디오', '헤어드라이어','베개','테이블','다이아','체어','밴드','한장','박스', '낚시','건조기','서큘','차량','공기청정기','삶통','선글라스','스탠드', '선풍기','자외선','배관','필터','물매','면도날', '치약','반신','욕기','다리미','근육통','동전','혈압','섬유','유연']\n",
    "health=['생식','레모나','코사놀','콜라겐','석류', '유산균', '착즙', '오메가','락토핏', '구미', '루테', '다이어트', '프리바이오틱스', '진액', '홍삼','팥물', '티톡', '비트', '양배추', '전립','두유','보틀', '홍합','비타민', '철갑상어', '히비스커스', '분말','해죽', '바이오']\n",
    "gagu=['하이바스','침대', '가구', '서랍', '소파', '수납', '이장','클라이너', '하부','원목', '도마', '화장', '베드룸', '프레임', '매트리스','협탁', '스티', '장형', '시공', '카우치','침실','거실','거울']\n",
    "bed=['대자리','침구', '슈퍼', '카페트', '호텔','커튼', '극세사', '순면', '싱글', '대형', '중형', '차렵', '러그','침대']\n",
    "goods=['리스틀릿','보스턴','가방','사첼','지갑','캐리올','케이프','여성','남성', '크로스', '토트', '트레킹', '팔찌', '슬립','숄더백', '목걸이', '순금', '워킹', '러닝', '주얼리', '부츠', '다이아몬드', '워치', '골드', '선글라스', '스니커즈', '체인', '골드바', '반지', '악어', '모자', '샌들', '컬렉션', '귀걸이', '방한','숄더', '핸드백', '아쿠아', '펌프스', '클러치','백', '코트', '머플러', '카드', '슬리퍼', '플랫슈즈', '다이아', '시계', '밍크', '쥬얼', '슈즈','버켓', '가죽', '버킷','린넨', '스카프', '보석', '쇼퍼', '장갑', '패딩', '웨이백', '카메라', '양산', '브릿지', '피아노', '벨트','남성화', '면도기', '퍼슈즈', '양모', '아동']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "3O5syqmlJN2z"
   },
   "outputs": [],
   "source": [
    "train_df['상품명'] = train_df['상품명'].apply(lambda x: x.replace('숏츠','쇼츠'))\n",
    "test_df['상품명'] = test_df['상품명'].apply(lambda x: x.replace('숏츠','쇼츠'))\n",
    "train_df['상품명'] = train_df['상품명'].apply(lambda x: x.replace('후라이팬','프라이팬'))\n",
    "test_df['상품명'] = test_df['상품명'].apply(lambda x: x.replace('후라이팬','프라이팬'))\n",
    "train_df['상품명'] = train_df['상품명'].apply(lambda x: x.replace('공청기','공기청정기'))\n",
    "test_df['상품명'] = test_df['상품명'].apply(lambda x: x.replace('공청기','공기청정기'))\n",
    "train_df['상품명'] = train_df['상품명'].apply(lambda x: x.replace('매트리스','매트릭스'))\n",
    "test_df['상품명'] = test_df['상품명'].apply(lambda x: x.replace('매트리스','매트릭스'))\n",
    "train_df['상품명'] = train_df['상품명'].apply(lambda x: x.replace('전기렌인지','전자레인지'))\n",
    "test_df['상품명'] = test_df['상품명'].apply(lambda x: x.replace('전기렌인지','전자레인지'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "FdcwZYy7MU56"
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "def make_word2vec(df,li,kind):\n",
    "  sock = df[df['상품군']==kind]['상품명'].unique()\n",
    "  sock_list=[]\n",
    "  for s in sock:\n",
    "    name_list=[]\n",
    "    for c in li:\n",
    "      if c in s:\n",
    "        name_list.append(c)\n",
    "    sock_list.append(name_list)\n",
    "  \n",
    "  kk=pd.DataFrame({'name':sock})\n",
    "\n",
    "  def apply_def(word,li=li):\n",
    "    word_list=[]\n",
    "    for s in li:\n",
    "      if s in word:\n",
    "        word_list.append(s)\n",
    "    return word_list\n",
    "\n",
    "  st_df=pd.DataFrame(kk['name'].apply(apply_def))\n",
    "\n",
    "  model = Word2Vec(sock_list, size=100, window = 2, min_count=1, workers=4, iter=100, sg=1)\n",
    "\n",
    "  vect_dict={}\n",
    "  del_list=[]\n",
    "  for name in li:\n",
    "    try:\n",
    "      model.wv.get_vector(name)\n",
    "      vect_dict[name] = model.wv.get_vector(name)\n",
    "    except:\n",
    "      del_list.append(name)\n",
    "  \n",
    "  word_df=pd.DataFrame(vect_dict).T.reset_index()\n",
    "  word_df.rename({'index':'name'},axis=1,inplace=True)\n",
    "\n",
    "  return word_df,kk[kk['name'].apply(apply_def).apply(lambda x: len(x))==0],kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "9fTlD1SpMc6q"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "def make_distancematrix(word_df):\n",
    "  ecd_list =[]\n",
    "  for name_1 in word_df['name'].unique():\n",
    "    dt_list = []\n",
    "    for name_2 in word_df['name'].unique():\n",
    "      dt = distance.euclidean(word_df.loc[word_df['name']==name_1,word_df.columns[1:]],word_df.loc[word_df['name']==name_2,word_df.columns[1:]])\n",
    "      dt_list.append(dt)\n",
    "    ecd_list.append(dt_list)\n",
    "\n",
    "  dt_df=pd.DataFrame(np.array(ecd_list),columns=word_df['name'].values,index=word_df['name'].values)\n",
    "  \n",
    "  return dt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Asgnk8PKMgMI"
   },
   "outputs": [],
   "source": [
    "def make_TDM(dt_df,stuff_frame):\n",
    "  for name in word_df['name']:\n",
    "    stuff_frame[name] = 0\n",
    "\n",
    "  for idx in stuff_frame.index:\n",
    "    name = stuff_frame.loc[idx,'name']\n",
    "    for word in stuff_frame.columns[1:]:\n",
    "      if word in name:\n",
    "        stuff_frame.loc[idx,word]=1\n",
    "    \n",
    "  stuff_frame.iloc[:,1:] = np.array(stuff_frame.iloc[:,1:]).dot(np.array(dt_df))\n",
    "  \n",
    "  return stuff_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "V5BIpGxxModT"
   },
   "outputs": [],
   "source": [
    "def make_kmeans_return(kk,word_list,num):\n",
    "  import matplotlib.pyplot as plt\n",
    "  from sklearn.cluster import KMeans as km\n",
    "\n",
    "  model = km(n_clusters =int(len(word_list)/num))\n",
    "  model.fit(kk.iloc[:,1:])\n",
    "\n",
    "  cd_df=pd.DataFrame({'name':kk['name'],\n",
    "                      'clusters':model.predict(kk.iloc[:,1:])})\n",
    "  \n",
    "  return cd_df,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "1JlF5D98MrDx"
   },
   "outputs": [],
   "source": [
    "stuff_dict={'의류':wear,\n",
    "            '속옷':under_wear,\n",
    "            '주방':kichen,\n",
    "            '농수축':food,\n",
    "            '이미용':care,\n",
    "            '가전':family,\n",
    "            '생활용품':life,\n",
    "            '건강기능':health,\n",
    "            '잡화':goods,\n",
    "            '가구':gagu,\n",
    "            '침구':bed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "l3LLAcqYMxiY"
   },
   "outputs": [],
   "source": [
    "cn_final = pd.DataFrame()\n",
    "cn_test = pd.DataFrame()\n",
    "\n",
    "for key in stuff_dict.keys():\n",
    "  word_df,stuff_not,stuff_frame=make_word2vec(train_df,stuff_dict[key],key)\n",
    "  dt_df= make_distancematrix(word_df)\n",
    "  stuff_frame  = make_TDM(dt_df,stuff_frame)\n",
    "  cn_df,model=make_kmeans_return(stuff_frame,stuff_dict[key],2)\n",
    "  cn_df['상품군']= key\n",
    "\n",
    "  cn_final = pd.concat([cn_final,cn_df],axis=0)\n",
    "\n",
    "  #test 데이터\n",
    "  t_n=pd.DataFrame({'name':test_df[test_df['상품군']==key]['상품명'].unique()})\n",
    "  for name in word_df['name']:\n",
    "    t_n[name]=0\n",
    "  \n",
    "  for idx in t_n.index:\n",
    "    name = t_n.loc[idx,'name']\n",
    "    for word in t_n.columns[1:]:\n",
    "      if word in name:\n",
    "        t_n.loc[idx,word]=1\n",
    "    \n",
    "    t_n.iloc[:,1:]= np.array(t_n.iloc[:,1:]).dot(np.array(dt_df))\n",
    "\n",
    "\n",
    "  cn_df=pd.DataFrame({'name':t_n['name'],\n",
    "                      'clusters':model.predict(t_n.iloc[:,1:])})\n",
    "  cn_df['상품군']=key\n",
    "\n",
    "\n",
    "  cn_test = pd.concat([cn_test,cn_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "fBGGBs72m-kI",
    "outputId": "64f14ab1-52a5-480a-8701-81c05a3b90a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clusters</th>\n",
       "      <th>상품군</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>테이트 남성 셀린니트3종</td>\n",
       "      <td>5</td>\n",
       "      <td>의류</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>테이트 여성 셀린니트3종</td>\n",
       "      <td>5</td>\n",
       "      <td>의류</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CERINI by PAT 남성 소프트 기모 릴렉스팬츠</td>\n",
       "      <td>12</td>\n",
       "      <td>의류</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>보코 리버시블 무스탕</td>\n",
       "      <td>4</td>\n",
       "      <td>의류</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CERINI by PAT 남성 풀패키지 기모니트 3종</td>\n",
       "      <td>6</td>\n",
       "      <td>의류</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>보몽드 헤르만 착번아웃 극세사 침구세트 SS(슈퍼싱글)</td>\n",
       "      <td>3</td>\n",
       "      <td>침구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>보몽드 카밀라 더블착번극세사 토퍼침구세트 SK(슈퍼킹)</td>\n",
       "      <td>6</td>\n",
       "      <td>침구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>보몽드 카밀라 더블착번극세사 토퍼침구세트 K(킹)</td>\n",
       "      <td>4</td>\n",
       "      <td>침구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>보몽드 카밀라 더블착번극세사 토퍼침구세트 Q(퀸)</td>\n",
       "      <td>4</td>\n",
       "      <td>침구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>보몽드 카밀라 더블착번극세사 토퍼침구세트 SS(슈퍼싱글)</td>\n",
       "      <td>3</td>\n",
       "      <td>침구</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1692 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name  clusters 상품군\n",
       "0                     테이트 남성 셀린니트3종         5  의류\n",
       "1                     테이트 여성 셀린니트3종         5  의류\n",
       "2     CERINI by PAT 남성 소프트 기모 릴렉스팬츠        12  의류\n",
       "3                       보코 리버시블 무스탕         4  의류\n",
       "4     CERINI by PAT 남성 풀패키지 기모니트 3종         6  의류\n",
       "..                              ...       ...  ..\n",
       "48   보몽드 헤르만 착번아웃 극세사 침구세트 SS(슈퍼싱글)         3  침구\n",
       "49   보몽드 카밀라 더블착번극세사 토퍼침구세트 SK(슈퍼킹)         6  침구\n",
       "50      보몽드 카밀라 더블착번극세사 토퍼침구세트 K(킹)         4  침구\n",
       "51      보몽드 카밀라 더블착번극세사 토퍼침구세트 Q(퀸)         4  침구\n",
       "52  보몽드 카밀라 더블착번극세사 토퍼침구세트 SS(슈퍼싱글)         3  침구\n",
       "\n",
       "[1692 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cn_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "u_k6xqm1nGVQ",
    "outputId": "41b12d29-3e2b-4bcb-e69e-6943bb167d7d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clusters</th>\n",
       "      <th>상품군</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>잭필드 남성  반팔셔츠 4종</td>\n",
       "      <td>2</td>\n",
       "      <td>의류</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>코몽트 남성 티셔츠 8종(시즌1)</td>\n",
       "      <td>2</td>\n",
       "      <td>의류</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>마르엘라로사티 린넨 베스트 세트[3월]</td>\n",
       "      <td>11</td>\n",
       "      <td>의류</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>라라쎄 쉬폰 롤업재킷 1종</td>\n",
       "      <td>11</td>\n",
       "      <td>의류</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>크리스티나앤코 시스루앙상블</td>\n",
       "      <td>11</td>\n",
       "      <td>의류</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>지나송 보노 화이트에디션 암막 커튼(슈퍼특대형)</td>\n",
       "      <td>0</td>\n",
       "      <td>침구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>한스데코 샤를 이중 암막 레이스 커튼(슈퍼특대형)</td>\n",
       "      <td>0</td>\n",
       "      <td>침구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>한스데코 샤를 이중 암막 레이스 커튼(특대형)</td>\n",
       "      <td>0</td>\n",
       "      <td>침구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>한스데코 샤를 이중 암막 레이스 커튼(대형)</td>\n",
       "      <td>0</td>\n",
       "      <td>침구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>한스데코 샤를 이중 암막 레이스 커튼(중형)</td>\n",
       "      <td>4</td>\n",
       "      <td>침구</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  clusters 상품군\n",
       "0               잭필드 남성  반팔셔츠 4종         2  의류\n",
       "1            코몽트 남성 티셔츠 8종(시즌1)         2  의류\n",
       "2         마르엘라로사티 린넨 베스트 세트[3월]        11  의류\n",
       "3                라라쎄 쉬폰 롤업재킷 1종        11  의류\n",
       "4                크리스티나앤코 시스루앙상블        11  의류\n",
       "..                          ...       ...  ..\n",
       "11   지나송 보노 화이트에디션 암막 커튼(슈퍼특대형)         0  침구\n",
       "12  한스데코 샤를 이중 암막 레이스 커튼(슈퍼특대형)         0  침구\n",
       "13    한스데코 샤를 이중 암막 레이스 커튼(특대형)         0  침구\n",
       "14     한스데코 샤를 이중 암막 레이스 커튼(대형)         0  침구\n",
       "15     한스데코 샤를 이중 암막 레이스 커튼(중형)         4  침구\n",
       "\n",
       "[349 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "nRJotr8enX_6"
   },
   "outputs": [],
   "source": [
    "train_group=cn_final.groupby('상품군')['clusters'].value_counts().reset_index(name='c')\n",
    "test_group=cn_test.groupby('상품군')['clusters'].value_counts().reset_index(name='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "ByJA1nubnlkI"
   },
   "outputs": [],
   "source": [
    "for idx in train_group.index:\n",
    "  train_group.loc[idx,'name_c']=idx\n",
    "train_group['name_c'] = train_group['name_c'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "i1sOiGKlnzPo"
   },
   "outputs": [],
   "source": [
    "for idx in test_group.index:\n",
    "  kind = test_group.loc[idx,'상품군']\n",
    "  cluster = test_group.loc[idx,'clusters']\n",
    "  test_group.loc[idx,'name_c'] = train_group.loc[(train_group['상품군']==kind)&(train_group['clusters']==cluster),'name_c'].values[0]\n",
    "test_group['name_c'] = test_group['name_c'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "f0tlYl2Wn5M_"
   },
   "outputs": [],
   "source": [
    "nc_train = cn_final.merge(train_group[['상품군','clusters','name_c']],on=['상품군','clusters'],how='left')[['상품군','name','name_c']].rename({'name': '상품명'}, axis='columns')\n",
    "nc_test = cn_test.merge(test_group[['상품군','clusters','name_c']],on=['상품군','clusters'],how='left')[['상품군','name','name_c']].rename({'name': '상품명'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "4hucrQlRoLG9",
    "outputId": "979df13f-2e79-4b42-f3df-82f012ae2bde"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>상품군</th>\n",
       "      <th>상품명</th>\n",
       "      <th>name_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>의류</td>\n",
       "      <td>테이트 남성 셀린니트3종</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>의류</td>\n",
       "      <td>테이트 여성 셀린니트3종</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>의류</td>\n",
       "      <td>CERINI by PAT 남성 소프트 기모 릴렉스팬츠</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>의류</td>\n",
       "      <td>보코 리버시블 무스탕</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>의류</td>\n",
       "      <td>CERINI by PAT 남성 풀패키지 기모니트 3종</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>침구</td>\n",
       "      <td>보몽드 헤르만 착번아웃 극세사 침구세트 SS(슈퍼싱글)</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>침구</td>\n",
       "      <td>보몽드 카밀라 더블착번극세사 토퍼침구세트 SK(슈퍼킹)</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>침구</td>\n",
       "      <td>보몽드 카밀라 더블착번극세사 토퍼침구세트 K(킹)</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>침구</td>\n",
       "      <td>보몽드 카밀라 더블착번극세사 토퍼침구세트 Q(퀸)</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>침구</td>\n",
       "      <td>보몽드 카밀라 더블착번극세사 토퍼침구세트 SS(슈퍼싱글)</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1692 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     상품군                              상품명  name_c\n",
       "0     의류                    테이트 남성 셀린니트3종     162\n",
       "1     의류                    테이트 여성 셀린니트3종     162\n",
       "2     의류    CERINI by PAT 남성 소프트 기모 릴렉스팬츠     170\n",
       "3     의류                      보코 리버시블 무스탕     173\n",
       "4     의류    CERINI by PAT 남성 풀패키지 기모니트 3종     161\n",
       "...   ..                              ...     ...\n",
       "1687  침구   보몽드 헤르만 착번아웃 극세사 침구세트 SS(슈퍼싱글)     267\n",
       "1688  침구   보몽드 카밀라 더블착번극세사 토퍼침구세트 SK(슈퍼킹)     266\n",
       "1689  침구      보몽드 카밀라 더블착번극세사 토퍼침구세트 K(킹)     263\n",
       "1690  침구      보몽드 카밀라 더블착번극세사 토퍼침구세트 Q(퀸)     263\n",
       "1691  침구  보몽드 카밀라 더블착번극세사 토퍼침구세트 SS(슈퍼싱글)     267\n",
       "\n",
       "[1692 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "1kVXnlyMohvV"
   },
   "outputs": [],
   "source": [
    "train_df=train_df.merge(nc_train[['상품명','name_c']],on='상품명',how='left')\n",
    "test_df=test_df.merge(nc_test[['상품명','name_c']],on='상품명',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "KpgGnT4Mq87z"
   },
   "outputs": [],
   "source": [
    "train_df.rename({'name_c':'중분류'}, axis='columns',inplace=True)\n",
    "test_df.rename({'name_c':'중분류'}, axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "z7DWRhYErND7"
   },
   "outputs": [],
   "source": [
    "test_df.drop(['cluster_dict','cc'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "jZxminMVr5J6"
   },
   "outputs": [],
   "source": [
    "train_df.rename({'clusters':'브랜드'},axis=1,inplace=True)\n",
    "test_df.rename({'new_clusters':'브랜드'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "Fmf7gWDamP0f"
   },
   "outputs": [],
   "source": [
    "train_df.drop('new_name', axis=1, inplace=True)\n",
    "test_df.drop('new_name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDgBECc_vtMw"
   },
   "source": [
    "### (11) 브랜드별, 중분류별 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "1ywTpg28HiKW"
   },
   "outputs": [],
   "source": [
    "def JensenShannon_similarity(df,time_list,st_list,cal_col):\n",
    "  '''\n",
    "  [함수 사용법]\n",
    "    X축에 들어갈 변수를 input_list 인덱싱 0번 자리(맨앞)에 둘 것\n",
    "    그 뒤로 기준을 잡고 싶은 변수들을 차례로 넣어 주면 됩니다.\n",
    "    from scipy.spatial import distance 꼭 할것!\n",
    "  '''\n",
    "\n",
    "\n",
    "  make_amt= df.groupby(time_list+st_list)[cal_col].sum().reset_index()\n",
    "  \n",
    "  '''pivot 만들기'''\n",
    "  amt_sum = make_amt.groupby(st_list)[cal_col].sum().reset_index(name='cal_col_sum')\n",
    "  amt_sum = amt_sum[amt_sum['cal_col_sum'] != 0] #JSD를 구할때 0이 있으면 문제가 생김\n",
    "  make_amt = make_amt.merge(amt_sum,on=st_list,how='left')\n",
    "  make_amt['cal_col_prob'] = make_amt[cal_col]/make_amt['cal_col_sum']\n",
    "\n",
    "  # pivot_table을 활용하여 long to wide 작업 실시\n",
    "  amt_pivot= pd.pivot_table(make_amt,\n",
    "                            index=st_list,\n",
    "                            columns=time_list,\n",
    "                            values='cal_col_prob').reset_index()\n",
    "  amt_pivot.fillna(0,inplace=True)\n",
    "\n",
    "  #피벗된 연도별 amt를 사용해 고객간의 유사도를 구해보자.\n",
    "  amt_array=np.array(amt_pivot.drop(st_list,axis=1))\n",
    "\n",
    "  js_similarity =[]\n",
    "  for row_r in range(amt_array.shape[0]):       \n",
    "    dt_list=[]\n",
    "    for row_c in range(amt_array.shape[0]):\n",
    "        #dt= js_divergence(amt_pivot.iloc[row_r,3:].values,amt_pivot.iloc[row_c,3:].values)\n",
    "        '''\n",
    "        js_divergence(만든 함수)로 하면 0값을 계산을 못함. \n",
    "        sqrt(js_divergence)인 distance.jensenshannon 함수 사용\n",
    "        '''\n",
    "        dt = distance.jensenshannon(amt_array[row_r,:],amt_array[row_c,:],2.0)\n",
    "        dt_list.append(dt)\n",
    "    js_similarity.append(dt_list)\n",
    "\n",
    "  js_frame =pd.DataFrame(np.array(js_similarity))\n",
    "  js_similarity = pd.concat([amt_pivot,js_frame],axis=1)\n",
    "\n",
    "  return amt_sum[st_list],js_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "vCqiJk_Suf1O"
   },
   "outputs": [],
   "source": [
    "def make_clustering(gp_df,time_list,st_list,cal_col,cluster_name,split_num=2):\n",
    "    st_series,df = JensenShannon_similarity(gp_df,time_list,st_list,cal_col)\n",
    "    df_s = df.iloc[:,-df.shape[0]:] # 클러스터링용 dataframe 생성\n",
    "    df_s.fillna(0,inplace=True)\n",
    "\n",
    "    #클러스터링\n",
    "    clustering = AgglomerativeClustering(n_clusters=int(df_s.shape[0]/split_num),\n",
    "                                      affinity='precomputed',\n",
    "                                      linkage='average')\n",
    "    clustering.fit(df_s)\n",
    "    \n",
    "    return_df = pd.DataFrame(st_series)         #pd.DataFrame(DataFrame) 오류X\n",
    "\n",
    "    print(return_df.shape,len(clustering.labels_))\n",
    "\n",
    "    return_df[cluster_name] = clustering.labels_\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "otN_tk9uSZYo"
   },
   "outputs": [],
   "source": [
    "train_df['판매단가bin'] = train_df['판매단가bin'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "id": "xb705q3-s5Bu",
    "outputId": "cd5cdd41-b4a2-41d1-8d64-210596775902"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(547, 1) 547\n",
      "(547, 1) 547\n",
      "(547, 1) 547\n",
      "(547, 1) 547\n",
      "(547, 1) 547\n",
      "(547, 1) 547\n",
      "(547, 1) 547\n",
      "(547, 1) 547\n",
      "(547, 1) 547\n",
      "(547, 1) 547\n",
      "(547, 1) 547\n",
      "(547, 1) 547\n",
      "(547, 1) 547\n",
      "(547, 1) 547\n",
      "(547, 1) 547\n",
      "(547, 1) 547\n",
      "(269, 1) 269\n",
      "(269, 1) 269\n",
      "(269, 1) 269\n",
      "(269, 1) 269\n",
      "(269, 1) 269\n",
      "(269, 1) 269\n",
      "(269, 1) 269\n",
      "(269, 1) 269\n",
      "(269, 1) 269\n",
      "(269, 1) 269\n",
      "(269, 1) 269\n",
      "(269, 1) 269\n",
      "(269, 1) 269\n",
      "(269, 1) 269\n",
      "(269, 1) 269\n",
      "(269, 1) 269\n"
     ]
    }
   ],
   "source": [
    "c1 = make_clustering(train_df, ['month'], ['브랜드'], '취급액', 'month_브랜드_취급액', split_num=2)\n",
    "c2 = make_clustering(train_df, ['hour'], ['브랜드'], '취급액', 'hour_브랜드_취급액', split_num=2)\n",
    "c3 = make_clustering(train_df, ['business_day'], ['브랜드'], '취급액', 'business_day_브랜드_취급액', split_num=2)\n",
    "c4 = make_clustering(train_df, ['season'], ['브랜드'], '취급액', 'season_브랜드_취급액', split_num=2)\n",
    "c5 = make_clustering(train_df, ['weekday'], ['브랜드'], '취급액', 'weekday_브랜드_취급액', split_num=2)\n",
    "c6 = make_clustering(train_df, ['weekofyear'], ['브랜드'], '취급액', 'weekofyear_브랜드_취급액', split_num=2)\n",
    "c7 = make_clustering(train_df, ['판매단가bin'], ['브랜드'], '취급액', '판매단가bin_브랜드_취급액', split_num=2)\n",
    "c8 = make_clustering(train_df, ['방송순서'], ['브랜드'], '취급액', '방송순서_브랜드_취급액', split_num=2)\n",
    "c9 = make_clustering(train_df, ['month'], ['브랜드'], '주문량', 'month_브랜드_주문량', split_num=2)\n",
    "c10 = make_clustering(train_df, ['hour'], ['브랜드'], '주문량', 'hour_브랜드_주문량', split_num=2)\n",
    "c11 = make_clustering(train_df, ['business_day'], ['브랜드'], '주문량', 'business_day_브랜드_주문량', split_num=2)\n",
    "c12 = make_clustering(train_df, ['season'], ['브랜드'], '주문량', 'season_브랜드_주문량', split_num=2)\n",
    "c13 = make_clustering(train_df, ['weekday'], ['브랜드'], '주문량', 'weekday_브랜드_주문량', split_num=2)\n",
    "c14 = make_clustering(train_df, ['weekofyear'], ['브랜드'], '주문량', 'weekofyear_브랜드_주문량', split_num=2)\n",
    "c15 = make_clustering(train_df, ['판매단가bin'], ['브랜드'], '주문량', '판매단가bin_브랜드_주문량', split_num=2)\n",
    "c16 = make_clustering(train_df, ['방송순서'], ['브랜드'], '주문량', '방송순서_브랜드_주문량', split_num=2)\n",
    "c17 = make_clustering(train_df, ['month'], ['중분류'], '취급액', 'month_중분류_취급액', split_num=2)\n",
    "c18 = make_clustering(train_df, ['hour'], ['중분류'], '취급액', 'hour_중분류_취급액', split_num=2)\n",
    "c19 = make_clustering(train_df, ['business_day'], ['중분류'], '취급액', 'business_day_중분류_취급액', split_num=2)\n",
    "c20 = make_clustering(train_df, ['season'], ['중분류'], '취급액', 'season_중분류_취급액', split_num=2)\n",
    "c21 = make_clustering(train_df, ['weekday'], ['중분류'], '취급액', 'weekday_중분류_취급액', split_num=2)\n",
    "c22 = make_clustering(train_df, ['weekofyear'], ['중분류'], '취급액', 'weekofyear_중분류_취급액', split_num=2)\n",
    "c23 = make_clustering(train_df, ['판매단가bin'], ['중분류'], '취급액', '판매단가bin_중분류_취급액', split_num=2)\n",
    "c24 = make_clustering(train_df, ['방송순서'], ['중분류'], '취급액', '방송순서_중분류_취급액', split_num=2)\n",
    "c25 = make_clustering(train_df, ['month'], ['중분류'], '주문량', 'month_중분류_주문량', split_num=2)\n",
    "c26 = make_clustering(train_df, ['hour'], ['중분류'], '주문량', 'hour_중분류_주문량', split_num=2)\n",
    "c27 = make_clustering(train_df, ['business_day'], ['중분류'], '주문량', 'business_day_중분류_주문량', split_num=2)\n",
    "c28 = make_clustering(train_df, ['season'], ['중분류'], '주문량', 'season_중분류_주문량', split_num=2)\n",
    "c29 = make_clustering(train_df, ['weekday'], ['중분류'], '주문량', 'weekday_중분류_주문량', split_num=2)\n",
    "c30 = make_clustering(train_df, ['weekofyear'], ['중분류'], '주문량', 'weekofyear_중분류_주문량', split_num=2)\n",
    "c31 = make_clustering(train_df, ['판매단가bin'], ['중분류'], '주문량', '판매단가bin_중분류_주문량', split_num=2)\n",
    "c32 = make_clustering(train_df, ['방송순서'], ['중분류'], '주문량', '방송순서_중분류_주문량', split_num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "ymkbGS9lmP0s"
   },
   "outputs": [],
   "source": [
    "train_df['브랜드_mean'] = train_df.groupby('브랜드')['취급액'].transform('mean')\n",
    "train_df['브랜드_median'] = train_df.groupby('브랜드')['취급액'].transform('median')\n",
    "train_df['브랜드_std'] = train_df.groupby('브랜드')['취급액'].transform('std')\n",
    "train_df['중분류_mean'] = train_df.groupby('중분류')['취급액'].transform('mean')\n",
    "train_df['중분류_median'] = train_df.groupby('중분류')['취급액'].transform('median')\n",
    "train_df['중분류_std'] = train_df.groupby('중분류')['취급액'].transform('std')\n",
    "t1 = train_df[['브랜드', '브랜드_mean']].drop_duplicates()\n",
    "t2 = train_df[['브랜드', '브랜드_median']].drop_duplicates()\n",
    "t3 = train_df[['브랜드', '브랜드_std']].drop_duplicates()\n",
    "t4 = train_df[['중분류', '중분류_mean']].drop_duplicates()\n",
    "t5 = train_df[['중분류', '중분류_median']].drop_duplicates()\n",
    "t6 = train_df[['중분류', '중분류_std']].drop_duplicates()\n",
    "test_df = pd.merge(test_df, t1, on='브랜드', how='left')\n",
    "test_df = pd.merge(test_df, t2, on='브랜드', how='left')\n",
    "test_df = pd.merge(test_df, t3, on='브랜드', how='left')\n",
    "test_df = pd.merge(test_df, t4, on='중분류', how='left')\n",
    "test_df = pd.merge(test_df, t5, on='중분류', how='left')\n",
    "test_df = pd.merge(test_df, t6, on='중분류', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "xWl0JpnLmP0u"
   },
   "outputs": [],
   "source": [
    "cl = [c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11, c12, c13, c14, c15, c16]\n",
    "cl2 = [c17, c18, c19, c20, c21, c22, c23, c24, c25, c26, c27, c28, c29, c30, c31, c32]\n",
    "for c in cl:\n",
    "  train_df = pd.merge(train_df, c, on='브랜드', how='left')\n",
    "  test_df = pd.merge(test_df, c, on='브랜드', how='left')\n",
    "for c in cl2:\n",
    "  train_df = pd.merge(train_df, c, on='중분류', how='left')\n",
    "  test_df = pd.merge(test_df, c, on='중분류', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gimWfBxQmP0v"
   },
   "source": [
    "###  (12) train에 존재하지만 test에는 존재하지 않는 마더코드, 상품코드를 브랜드, 중분류로 비교 후 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "kt-xUPv-mP0w"
   },
   "outputs": [],
   "source": [
    "ma = list(train_df['마더코드'].unique())\n",
    "sa = list(train_df['상품코드'].unique())\n",
    "for i in test_df.index:\n",
    "  if test_df.loc[i, '상품코드'] not in sa:\n",
    "    t = train_df[train_df['중분류'] == test_df.loc[i, '중분류']][['상품코드', '판매단가']].drop_duplicates()\n",
    "    t['판'] = test_df.loc[i, '판매단가']\n",
    "    t['판매'] = np.abs(t['판'] - t['판매단가'])\n",
    "    if len(t) > 0:\n",
    "      test_df.loc[i, '상품코드'] = t[t['판매'] == t['판매'].min()]['상품코드'].values[0]\n",
    "  if test_df.loc[i, '마더코드'] not in ma:\n",
    "    tt = train_df[train_df['브랜드'] == test_df.loc[i, '브랜드']][['마더코드', '판매단가']].drop_duplicates()\n",
    "    tt['판'] = test_df.loc[i, '판매단가']\n",
    "    tt['판매'] = np.abs(tt['판'] - tt['판매단가'])\n",
    "    if len(tt) > 0:\n",
    "      test_df.loc[i, '마더코드'] = tt[tt['판매'] == tt['판매'].min()]['마더코드'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22idJnGimP0y"
   },
   "source": [
    "# Modeling\n",
    "- LightGBM 사용\n",
    "- 취급액이 NaN인 행은 제거 후 학습\n",
    "- 상품군별로 Stratied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "aiJAXZcHmP0y"
   },
   "outputs": [],
   "source": [
    "trn_drop_cols = ['방송일시', '상품명', '취급액', '주문량', '일시', '판매단가bin']\n",
    "tes_drop_cols = ['방송일시', '상품명', '취급액', '일시', '판매단가bin']\n",
    "x_train = train_df[(train_df['상품군'] != '무형') & (train_df['취급액'].isna() != True)].drop(trn_drop_cols, axis=1)\n",
    "y_train = np.log(train_df[(train_df['상품군'] != '무형') & (train_df['취급액'].isna() != True)][['취급액']])\n",
    "x_test = test_df.drop(tes_drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "MfEa5HANTo8G"
   },
   "outputs": [],
   "source": [
    "x_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "OkQMxpvXmP01"
   },
   "outputs": [],
   "source": [
    "cat_fea = ['상품군', '마더코드', '상품코드', 'month', 'day', 'hour', 'minute', 'weekday', 'weekofyear', 'season', 'holiday', 'business_day', 'Primetime', 'Swingtime', '브랜드', 'month_브랜드_취급액', 'hour_브랜드_취급액', 'business_day_브랜드_취급액', 'season_브랜드_취급액', 'weekday_브랜드_취급액', 'weekofyear_브랜드_취급액', '판매단가bin_브랜드_취급액', '방송순서_브랜드_취급액', 'month_브랜드_주문량', 'hour_브랜드_주문량', 'business_day_브랜드_주문량', 'season_브랜드_주문량', 'weekday_브랜드_주문량', 'weekofyear_브랜드_주문량', '판매단가bin_브랜드_주문량', '방송순서_브랜드_주문량', 'month_중분류_취급액', 'hour_중분류_취급액', 'business_day_중분류_취급액', 'season_중분류_취급액', 'weekday_중분류_취급액', 'weekofyear_중분류_취급액', '판매단가bin_중분류_취급액', '방송순서_중분류_취급액', 'month_중분류_주문량', 'hour_중분류_주문량', 'business_day_중분류_주문량', 'season_중분류_주문량', 'weekday_중분류_주문량', 'weekofyear_중분류_주문량', '판매단가bin_중분류_주문량', '방송순서_중분류_주문량']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "LDoLPn_kM9Hg",
    "outputId": "b08877b8-8544-45bf-965f-1ed0a18931a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>노출(분)</th>\n",
       "      <th>마더코드</th>\n",
       "      <th>상품코드</th>\n",
       "      <th>상품군</th>\n",
       "      <th>판매단가</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>business_day</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>temp_median</th>\n",
       "      <th>temp_std</th>\n",
       "      <th>rain_mean</th>\n",
       "      <th>rain_median</th>\n",
       "      <th>rain_std</th>\n",
       "      <th>wind_mean</th>\n",
       "      <th>wind_median</th>\n",
       "      <th>wind_std</th>\n",
       "      <th>wet_mean</th>\n",
       "      <th>wet_median</th>\n",
       "      <th>wet_std</th>\n",
       "      <th>mis_mean</th>\n",
       "      <th>mis_median</th>\n",
       "      <th>mis_std</th>\n",
       "      <th>Primetime</th>\n",
       "      <th>Swingtime</th>\n",
       "      <th>view_sum</th>\n",
       "      <th>view_mean</th>\n",
       "      <th>view_std</th>\n",
       "      <th>방송순서</th>\n",
       "      <th>실제노출</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>중분류</th>\n",
       "      <th>브랜드_mean</th>\n",
       "      <th>브랜드_median</th>\n",
       "      <th>브랜드_std</th>\n",
       "      <th>중분류_mean</th>\n",
       "      <th>중분류_median</th>\n",
       "      <th>중분류_std</th>\n",
       "      <th>month_브랜드_취급액</th>\n",
       "      <th>hour_브랜드_취급액</th>\n",
       "      <th>business_day_브랜드_취급액</th>\n",
       "      <th>season_브랜드_취급액</th>\n",
       "      <th>weekday_브랜드_취급액</th>\n",
       "      <th>weekofyear_브랜드_취급액</th>\n",
       "      <th>판매단가bin_브랜드_취급액</th>\n",
       "      <th>방송순서_브랜드_취급액</th>\n",
       "      <th>month_브랜드_주문량</th>\n",
       "      <th>hour_브랜드_주문량</th>\n",
       "      <th>business_day_브랜드_주문량</th>\n",
       "      <th>season_브랜드_주문량</th>\n",
       "      <th>weekday_브랜드_주문량</th>\n",
       "      <th>weekofyear_브랜드_주문량</th>\n",
       "      <th>판매단가bin_브랜드_주문량</th>\n",
       "      <th>방송순서_브랜드_주문량</th>\n",
       "      <th>month_중분류_취급액</th>\n",
       "      <th>hour_중분류_취급액</th>\n",
       "      <th>business_day_중분류_취급액</th>\n",
       "      <th>season_중분류_취급액</th>\n",
       "      <th>weekday_중분류_취급액</th>\n",
       "      <th>weekofyear_중분류_취급액</th>\n",
       "      <th>판매단가bin_중분류_취급액</th>\n",
       "      <th>방송순서_중분류_취급액</th>\n",
       "      <th>month_중분류_주문량</th>\n",
       "      <th>hour_중분류_주문량</th>\n",
       "      <th>business_day_중분류_주문량</th>\n",
       "      <th>season_중분류_주문량</th>\n",
       "      <th>weekday_중분류_주문량</th>\n",
       "      <th>weekofyear_중분류_주문량</th>\n",
       "      <th>판매단가bin_중분류_주문량</th>\n",
       "      <th>방송순서_중분류_주문량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>100346</td>\n",
       "      <td>201072</td>\n",
       "      <td>1</td>\n",
       "      <td>39900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.309524</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>4.773668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.554778</td>\n",
       "      <td>63.380952</td>\n",
       "      <td>62.0</td>\n",
       "      <td>15.078051</td>\n",
       "      <td>37.888889</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.594008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.633</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25</td>\n",
       "      <td>162.0</td>\n",
       "      <td>9.410607e+06</td>\n",
       "      <td>6672000.0</td>\n",
       "      <td>9.458556e+06</td>\n",
       "      <td>1.653506e+07</td>\n",
       "      <td>13187000.0</td>\n",
       "      <td>1.237883e+07</td>\n",
       "      <td>157.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   노출(분)    마더코드    상품코드  ...  weekofyear_중분류_주문량  판매단가bin_중분류_주문량  방송순서_중분류_주문량\n",
       "0   20.0  100346  201072  ...                18.0             28.0          44.0\n",
       "\n",
       "[1 rows x 76 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def a(x):\n",
    "  d1 = {'의류': 1, '속옷': 2, '주방': 3, '농수축': 4, '이미용': 5, '가전': 6, '생활용품': 7,\n",
    "          '건강기능': 8, '잡화': 9, '가구': 10, '침구': 11, '무형': 12}\n",
    "  return d1[x]\n",
    "x_train['상품군'] = x_train['상품군'].map(a)\n",
    "x_test['상품군'] = x_test['상품군'].map(a)\n",
    "x_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "nimNyX2jmP03",
    "outputId": "5b59230d-117d-4ac9-f00a-a71dc87dad0b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>노출(분)</th>\n",
       "      <th>마더코드</th>\n",
       "      <th>상품코드</th>\n",
       "      <th>상품군</th>\n",
       "      <th>판매단가</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>business_day</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>temp_median</th>\n",
       "      <th>temp_std</th>\n",
       "      <th>rain_mean</th>\n",
       "      <th>rain_median</th>\n",
       "      <th>rain_std</th>\n",
       "      <th>wind_mean</th>\n",
       "      <th>wind_median</th>\n",
       "      <th>wind_std</th>\n",
       "      <th>wet_mean</th>\n",
       "      <th>wet_median</th>\n",
       "      <th>wet_std</th>\n",
       "      <th>mis_mean</th>\n",
       "      <th>mis_median</th>\n",
       "      <th>mis_std</th>\n",
       "      <th>Primetime</th>\n",
       "      <th>Swingtime</th>\n",
       "      <th>view_sum</th>\n",
       "      <th>view_mean</th>\n",
       "      <th>view_std</th>\n",
       "      <th>방송순서</th>\n",
       "      <th>실제노출</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>중분류</th>\n",
       "      <th>브랜드_mean</th>\n",
       "      <th>브랜드_median</th>\n",
       "      <th>브랜드_std</th>\n",
       "      <th>중분류_mean</th>\n",
       "      <th>중분류_median</th>\n",
       "      <th>중분류_std</th>\n",
       "      <th>month_브랜드_취급액</th>\n",
       "      <th>hour_브랜드_취급액</th>\n",
       "      <th>business_day_브랜드_취급액</th>\n",
       "      <th>season_브랜드_취급액</th>\n",
       "      <th>weekday_브랜드_취급액</th>\n",
       "      <th>weekofyear_브랜드_취급액</th>\n",
       "      <th>판매단가bin_브랜드_취급액</th>\n",
       "      <th>방송순서_브랜드_취급액</th>\n",
       "      <th>month_브랜드_주문량</th>\n",
       "      <th>hour_브랜드_주문량</th>\n",
       "      <th>business_day_브랜드_주문량</th>\n",
       "      <th>season_브랜드_주문량</th>\n",
       "      <th>weekday_브랜드_주문량</th>\n",
       "      <th>weekofyear_브랜드_주문량</th>\n",
       "      <th>판매단가bin_브랜드_주문량</th>\n",
       "      <th>방송순서_브랜드_주문량</th>\n",
       "      <th>month_중분류_취급액</th>\n",
       "      <th>hour_중분류_취급액</th>\n",
       "      <th>business_day_중분류_취급액</th>\n",
       "      <th>season_중분류_취급액</th>\n",
       "      <th>weekday_중분류_취급액</th>\n",
       "      <th>weekofyear_중분류_취급액</th>\n",
       "      <th>판매단가bin_중분류_취급액</th>\n",
       "      <th>방송순서_중분류_취급액</th>\n",
       "      <th>month_중분류_주문량</th>\n",
       "      <th>hour_중분류_주문량</th>\n",
       "      <th>business_day_중분류_주문량</th>\n",
       "      <th>season_중분류_주문량</th>\n",
       "      <th>weekday_중분류_주문량</th>\n",
       "      <th>weekofyear_중분류_주문량</th>\n",
       "      <th>판매단가bin_중분류_주문량</th>\n",
       "      <th>방송순서_중분류_주문량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>100346</td>\n",
       "      <td>201072</td>\n",
       "      <td>1</td>\n",
       "      <td>39900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.309524</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>4.773668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.554778</td>\n",
       "      <td>63.380952</td>\n",
       "      <td>62.0</td>\n",
       "      <td>15.078051</td>\n",
       "      <td>37.888889</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.594008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.633</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25</td>\n",
       "      <td>162.0</td>\n",
       "      <td>9.410607e+06</td>\n",
       "      <td>6672000.0</td>\n",
       "      <td>9.458556e+06</td>\n",
       "      <td>1.653506e+07</td>\n",
       "      <td>13187000.0</td>\n",
       "      <td>1.237883e+07</td>\n",
       "      <td>157</td>\n",
       "      <td>168</td>\n",
       "      <td>24</td>\n",
       "      <td>263</td>\n",
       "      <td>181</td>\n",
       "      <td>121</td>\n",
       "      <td>271</td>\n",
       "      <td>188</td>\n",
       "      <td>176</td>\n",
       "      <td>215</td>\n",
       "      <td>88</td>\n",
       "      <td>191</td>\n",
       "      <td>207</td>\n",
       "      <td>227</td>\n",
       "      <td>151</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   노출(분)    마더코드    상품코드  ...  weekofyear_중분류_주문량  판매단가bin_중분류_주문량  방송순서_중분류_주문량\n",
       "0   20.0  100346  201072  ...                  18               28            44\n",
       "\n",
       "[1 rows x 76 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = ['Primetime', 'Swingtime', 'month_브랜드_취급액', 'hour_브랜드_취급액', 'business_day_브랜드_취급액', 'season_브랜드_취급액', 'weekday_브랜드_취급액', 'weekofyear_브랜드_취급액', '판매단가bin_브랜드_취급액', '방송순서_브랜드_취급액', 'month_브랜드_주문량', 'hour_브랜드_주문량', 'business_day_브랜드_주문량', 'season_브랜드_주문량', 'weekday_브랜드_주문량', 'weekofyear_브랜드_주문량', '판매단가bin_브랜드_주문량', '방송순서_브랜드_주문량', 'month_중분류_취급액', 'hour_중분류_취급액', 'business_day_중분류_취급액', 'season_중분류_취급액', 'weekday_중분류_취급액', 'weekofyear_중분류_취급액', '판매단가bin_중분류_취급액', '방송순서_중분류_취급액', 'month_중분류_주문량', 'hour_중분류_주문량', 'business_day_중분류_주문량', 'season_중분류_주문량', 'weekday_중분류_주문량', 'weekofyear_중분류_주문량', '판매단가bin_중분류_주문량', '방송순서_중분류_주문량']\n",
    "for c in l1:\n",
    "  x_train[c] = x_train[c].astype('int')\n",
    "  x_test[c] = x_test[c].astype('int')\n",
    "x_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "iKBMf74TmP04"
   },
   "outputs": [],
   "source": [
    "lgb_params = {'num_leaves':10,\n",
    "              'learning_rate':0.05,\n",
    "              'max_depth':6,\n",
    "              'boosting':'gbdt',\n",
    "              'objective':'regression',\n",
    "              'metric':'mape',\n",
    "              'lambda_l1':0.98,\n",
    "              'lambda_l2':0.7,\n",
    "              'min_data_in_leaf':1,\n",
    "              'bagging_fraction':0.9,\n",
    "              'feature_fraction':0.9,\n",
    "              'feature_fraction_seed':42,\n",
    "              'bagging_seed':42,\n",
    "              'seed':42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XTiU6CrjmP08",
    "outputId": "20b03564-e9ed-4bcd-ade1-eec4c2ad40f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold num_: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's mape: 0.0195474\tvalid_1's mape: 0.0206163\n",
      "[200]\ttraining's mape: 0.0176359\tvalid_1's mape: 0.0191498\n",
      "[300]\ttraining's mape: 0.0167646\tvalid_1's mape: 0.0186116\n",
      "[400]\ttraining's mape: 0.0161713\tvalid_1's mape: 0.0183142\n",
      "[500]\ttraining's mape: 0.0156988\tvalid_1's mape: 0.0181102\n",
      "[600]\ttraining's mape: 0.0152926\tvalid_1's mape: 0.0179185\n",
      "[700]\ttraining's mape: 0.0149379\tvalid_1's mape: 0.0177449\n",
      "[800]\ttraining's mape: 0.0146519\tvalid_1's mape: 0.0176374\n",
      "[900]\ttraining's mape: 0.0144117\tvalid_1's mape: 0.0175439\n",
      "[1000]\ttraining's mape: 0.0141862\tvalid_1's mape: 0.0174724\n",
      "[1100]\ttraining's mape: 0.0139666\tvalid_1's mape: 0.0174084\n",
      "[1200]\ttraining's mape: 0.0137821\tvalid_1's mape: 0.0173493\n",
      "[1300]\ttraining's mape: 0.0136047\tvalid_1's mape: 0.0172959\n",
      "[1400]\ttraining's mape: 0.0134424\tvalid_1's mape: 0.0172599\n",
      "[1500]\ttraining's mape: 0.0132881\tvalid_1's mape: 0.0172209\n",
      "[1600]\ttraining's mape: 0.0131436\tvalid_1's mape: 0.0171821\n",
      "[1700]\ttraining's mape: 0.0130096\tvalid_1's mape: 0.0171493\n",
      "[1800]\ttraining's mape: 0.0128827\tvalid_1's mape: 0.0171276\n",
      "[1900]\ttraining's mape: 0.0127628\tvalid_1's mape: 0.0171048\n",
      "[2000]\ttraining's mape: 0.012645\tvalid_1's mape: 0.0170724\n",
      "[2100]\ttraining's mape: 0.012539\tvalid_1's mape: 0.0170441\n",
      "[2200]\ttraining's mape: 0.0124261\tvalid_1's mape: 0.0170229\n",
      "[2300]\ttraining's mape: 0.0123228\tvalid_1's mape: 0.0169986\n",
      "[2400]\ttraining's mape: 0.0122207\tvalid_1's mape: 0.0169761\n",
      "[2500]\ttraining's mape: 0.0121148\tvalid_1's mape: 0.0169543\n",
      "[2600]\ttraining's mape: 0.0120209\tvalid_1's mape: 0.0169365\n",
      "[2700]\ttraining's mape: 0.0119323\tvalid_1's mape: 0.0169522\n",
      "Early stopping, best iteration is:\n",
      "[2626]\ttraining's mape: 0.0119978\tvalid_1's mape: 0.0169359\n",
      "fold num_: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's mape: 0.0195178\tvalid_1's mape: 0.0204415\n",
      "[200]\ttraining's mape: 0.0175962\tvalid_1's mape: 0.0189159\n",
      "[300]\ttraining's mape: 0.0167086\tvalid_1's mape: 0.0183587\n",
      "[400]\ttraining's mape: 0.0160983\tvalid_1's mape: 0.0180418\n",
      "[500]\ttraining's mape: 0.015638\tvalid_1's mape: 0.0178093\n",
      "[600]\ttraining's mape: 0.0152649\tvalid_1's mape: 0.0176409\n",
      "[700]\ttraining's mape: 0.0149234\tvalid_1's mape: 0.0174976\n",
      "[800]\ttraining's mape: 0.0146327\tvalid_1's mape: 0.0173989\n",
      "[900]\ttraining's mape: 0.014383\tvalid_1's mape: 0.017315\n",
      "[1000]\ttraining's mape: 0.0141674\tvalid_1's mape: 0.0172523\n",
      "[1100]\ttraining's mape: 0.0139602\tvalid_1's mape: 0.0171769\n",
      "[1200]\ttraining's mape: 0.0137696\tvalid_1's mape: 0.0171273\n",
      "[1300]\ttraining's mape: 0.0135917\tvalid_1's mape: 0.0170628\n",
      "[1400]\ttraining's mape: 0.0134393\tvalid_1's mape: 0.0170125\n",
      "[1500]\ttraining's mape: 0.0132733\tvalid_1's mape: 0.016974\n",
      "[1600]\ttraining's mape: 0.013126\tvalid_1's mape: 0.0169455\n",
      "[1700]\ttraining's mape: 0.0129995\tvalid_1's mape: 0.0169326\n",
      "[1800]\ttraining's mape: 0.0128668\tvalid_1's mape: 0.0169127\n",
      "[1900]\ttraining's mape: 0.0127532\tvalid_1's mape: 0.0168859\n",
      "[2000]\ttraining's mape: 0.0126409\tvalid_1's mape: 0.0168712\n",
      "[2100]\ttraining's mape: 0.0125355\tvalid_1's mape: 0.016861\n",
      "[2200]\ttraining's mape: 0.0124278\tvalid_1's mape: 0.0168483\n",
      "[2300]\ttraining's mape: 0.012315\tvalid_1's mape: 0.0168473\n",
      "Early stopping, best iteration is:\n",
      "[2231]\ttraining's mape: 0.012389\tvalid_1's mape: 0.0168381\n",
      "fold num_: 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's mape: 0.0196508\tvalid_1's mape: 0.0198907\n",
      "[200]\ttraining's mape: 0.0177376\tvalid_1's mape: 0.0184511\n",
      "[300]\ttraining's mape: 0.0168541\tvalid_1's mape: 0.0178612\n",
      "[400]\ttraining's mape: 0.016276\tvalid_1's mape: 0.0175233\n",
      "[500]\ttraining's mape: 0.0158039\tvalid_1's mape: 0.0173038\n",
      "[600]\ttraining's mape: 0.0153873\tvalid_1's mape: 0.017118\n",
      "[700]\ttraining's mape: 0.0150447\tvalid_1's mape: 0.0170047\n",
      "[800]\ttraining's mape: 0.0147539\tvalid_1's mape: 0.016923\n",
      "[900]\ttraining's mape: 0.0144997\tvalid_1's mape: 0.0168719\n",
      "[1000]\ttraining's mape: 0.0142615\tvalid_1's mape: 0.016813\n",
      "[1100]\ttraining's mape: 0.0140562\tvalid_1's mape: 0.016754\n",
      "[1200]\ttraining's mape: 0.0138524\tvalid_1's mape: 0.0167287\n",
      "[1300]\ttraining's mape: 0.0136809\tvalid_1's mape: 0.0167049\n",
      "[1400]\ttraining's mape: 0.0135203\tvalid_1's mape: 0.016689\n",
      "[1500]\ttraining's mape: 0.0133637\tvalid_1's mape: 0.0166776\n",
      "[1600]\ttraining's mape: 0.0132105\tvalid_1's mape: 0.016683\n",
      "Early stopping, best iteration is:\n",
      "[1501]\ttraining's mape: 0.0133613\tvalid_1's mape: 0.0166762\n",
      "fold num_: 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's mape: 0.0194666\tvalid_1's mape: 0.0210771\n",
      "[200]\ttraining's mape: 0.0175243\tvalid_1's mape: 0.0197146\n",
      "[300]\ttraining's mape: 0.0166491\tvalid_1's mape: 0.019141\n",
      "[400]\ttraining's mape: 0.0160378\tvalid_1's mape: 0.0188161\n",
      "[500]\ttraining's mape: 0.0155623\tvalid_1's mape: 0.0185394\n",
      "[600]\ttraining's mape: 0.0151571\tvalid_1's mape: 0.0183444\n",
      "[700]\ttraining's mape: 0.014801\tvalid_1's mape: 0.0181905\n",
      "[800]\ttraining's mape: 0.0145128\tvalid_1's mape: 0.0180841\n",
      "[900]\ttraining's mape: 0.0142687\tvalid_1's mape: 0.0179916\n",
      "[1000]\ttraining's mape: 0.0140513\tvalid_1's mape: 0.0179171\n",
      "[1100]\ttraining's mape: 0.0138525\tvalid_1's mape: 0.0178498\n",
      "[1200]\ttraining's mape: 0.0136723\tvalid_1's mape: 0.0178023\n",
      "[1300]\ttraining's mape: 0.0134928\tvalid_1's mape: 0.0177414\n",
      "[1400]\ttraining's mape: 0.0133224\tvalid_1's mape: 0.017679\n",
      "[1500]\ttraining's mape: 0.0131577\tvalid_1's mape: 0.0176434\n",
      "[1600]\ttraining's mape: 0.0130217\tvalid_1's mape: 0.0176165\n",
      "[1700]\ttraining's mape: 0.0128787\tvalid_1's mape: 0.0175761\n",
      "[1800]\ttraining's mape: 0.0127499\tvalid_1's mape: 0.0175561\n",
      "[1900]\ttraining's mape: 0.0126318\tvalid_1's mape: 0.0175341\n",
      "[2000]\ttraining's mape: 0.0125289\tvalid_1's mape: 0.0175112\n",
      "[2100]\ttraining's mape: 0.0124175\tvalid_1's mape: 0.0174914\n",
      "[2200]\ttraining's mape: 0.0123185\tvalid_1's mape: 0.0174818\n",
      "[2300]\ttraining's mape: 0.0122229\tvalid_1's mape: 0.0174701\n",
      "[2400]\ttraining's mape: 0.0121346\tvalid_1's mape: 0.0174612\n",
      "Early stopping, best iteration is:\n",
      "[2382]\ttraining's mape: 0.0121489\tvalid_1's mape: 0.0174584\n",
      "fold num_: 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's mape: 0.0195392\tvalid_1's mape: 0.0208618\n",
      "[200]\ttraining's mape: 0.0175848\tvalid_1's mape: 0.0194092\n",
      "[300]\ttraining's mape: 0.0166807\tvalid_1's mape: 0.0189105\n",
      "[400]\ttraining's mape: 0.0160795\tvalid_1's mape: 0.018582\n",
      "[500]\ttraining's mape: 0.0156124\tvalid_1's mape: 0.0183271\n",
      "[600]\ttraining's mape: 0.0152226\tvalid_1's mape: 0.0181427\n",
      "[700]\ttraining's mape: 0.0149069\tvalid_1's mape: 0.0180072\n",
      "[800]\ttraining's mape: 0.0146106\tvalid_1's mape: 0.0178755\n",
      "[900]\ttraining's mape: 0.0143674\tvalid_1's mape: 0.0177793\n",
      "[1000]\ttraining's mape: 0.014143\tvalid_1's mape: 0.0176884\n",
      "[1100]\ttraining's mape: 0.0139287\tvalid_1's mape: 0.0176232\n",
      "[1200]\ttraining's mape: 0.0137408\tvalid_1's mape: 0.0175808\n",
      "[1300]\ttraining's mape: 0.013567\tvalid_1's mape: 0.0175443\n",
      "[1400]\ttraining's mape: 0.0134035\tvalid_1's mape: 0.0174962\n",
      "[1500]\ttraining's mape: 0.0132468\tvalid_1's mape: 0.0174709\n",
      "[1600]\ttraining's mape: 0.0130996\tvalid_1's mape: 0.0174649\n",
      "[1700]\ttraining's mape: 0.0129657\tvalid_1's mape: 0.0174509\n",
      "[1800]\ttraining's mape: 0.0128261\tvalid_1's mape: 0.0174314\n",
      "[1900]\ttraining's mape: 0.0127145\tvalid_1's mape: 0.0174182\n",
      "[2000]\ttraining's mape: 0.0125993\tvalid_1's mape: 0.0173946\n",
      "[2100]\ttraining's mape: 0.0124822\tvalid_1's mape: 0.0173805\n",
      "[2200]\ttraining's mape: 0.0123734\tvalid_1's mape: 0.0173751\n",
      "[2300]\ttraining's mape: 0.0122774\tvalid_1's mape: 0.0173712\n",
      "[2400]\ttraining's mape: 0.0121676\tvalid_1's mape: 0.0173769\n",
      "Early stopping, best iteration is:\n",
      "[2305]\ttraining's mape: 0.0122729\tvalid_1's mape: 0.0173698\n",
      "fold num_: 6\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's mape: 0.019553\tvalid_1's mape: 0.0206689\n",
      "[200]\ttraining's mape: 0.0176445\tvalid_1's mape: 0.0193215\n",
      "[300]\ttraining's mape: 0.0167584\tvalid_1's mape: 0.0187422\n",
      "[400]\ttraining's mape: 0.0161626\tvalid_1's mape: 0.0184191\n",
      "[500]\ttraining's mape: 0.0156993\tvalid_1's mape: 0.018165\n",
      "[600]\ttraining's mape: 0.0153293\tvalid_1's mape: 0.017989\n",
      "[700]\ttraining's mape: 0.0149918\tvalid_1's mape: 0.0178354\n",
      "[800]\ttraining's mape: 0.0146913\tvalid_1's mape: 0.0177077\n",
      "[900]\ttraining's mape: 0.0144423\tvalid_1's mape: 0.0176059\n",
      "[1000]\ttraining's mape: 0.0142322\tvalid_1's mape: 0.0175301\n",
      "[1100]\ttraining's mape: 0.0140422\tvalid_1's mape: 0.0174605\n",
      "[1200]\ttraining's mape: 0.0138422\tvalid_1's mape: 0.017401\n",
      "[1300]\ttraining's mape: 0.0136629\tvalid_1's mape: 0.0173497\n",
      "[1400]\ttraining's mape: 0.0135037\tvalid_1's mape: 0.0172905\n",
      "[1500]\ttraining's mape: 0.0133513\tvalid_1's mape: 0.0172656\n",
      "[1600]\ttraining's mape: 0.0131941\tvalid_1's mape: 0.0172298\n",
      "[1700]\ttraining's mape: 0.0130603\tvalid_1's mape: 0.0171894\n",
      "[1800]\ttraining's mape: 0.0129332\tvalid_1's mape: 0.0171517\n",
      "[1900]\ttraining's mape: 0.012805\tvalid_1's mape: 0.0171182\n",
      "[2000]\ttraining's mape: 0.0126883\tvalid_1's mape: 0.0170785\n",
      "[2100]\ttraining's mape: 0.0125806\tvalid_1's mape: 0.0170666\n",
      "[2200]\ttraining's mape: 0.012478\tvalid_1's mape: 0.0170459\n",
      "[2300]\ttraining's mape: 0.0123693\tvalid_1's mape: 0.0170235\n",
      "[2400]\ttraining's mape: 0.0122618\tvalid_1's mape: 0.0170187\n",
      "[2500]\ttraining's mape: 0.0121668\tvalid_1's mape: 0.0170115\n",
      "[2600]\ttraining's mape: 0.012064\tvalid_1's mape: 0.0169783\n",
      "[2700]\ttraining's mape: 0.0119825\tvalid_1's mape: 0.0169542\n",
      "[2800]\ttraining's mape: 0.0118896\tvalid_1's mape: 0.016943\n",
      "[2900]\ttraining's mape: 0.0117969\tvalid_1's mape: 0.016936\n",
      "[3000]\ttraining's mape: 0.0117133\tvalid_1's mape: 0.016917\n",
      "[3100]\ttraining's mape: 0.011631\tvalid_1's mape: 0.0169098\n",
      "[3200]\ttraining's mape: 0.0115481\tvalid_1's mape: 0.0169122\n",
      "Early stopping, best iteration is:\n",
      "[3134]\ttraining's mape: 0.0116023\tvalid_1's mape: 0.0169031\n",
      "fold num_: 7\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's mape: 0.0195875\tvalid_1's mape: 0.0203083\n",
      "[200]\ttraining's mape: 0.0176283\tvalid_1's mape: 0.0189737\n",
      "[300]\ttraining's mape: 0.0167743\tvalid_1's mape: 0.0184988\n",
      "[400]\ttraining's mape: 0.0161549\tvalid_1's mape: 0.0181832\n",
      "[500]\ttraining's mape: 0.0156954\tvalid_1's mape: 0.017956\n",
      "[600]\ttraining's mape: 0.0152884\tvalid_1's mape: 0.017778\n",
      "[700]\ttraining's mape: 0.0149551\tvalid_1's mape: 0.0176456\n",
      "[800]\ttraining's mape: 0.014666\tvalid_1's mape: 0.0175274\n",
      "[900]\ttraining's mape: 0.0144047\tvalid_1's mape: 0.0174329\n",
      "[1000]\ttraining's mape: 0.014179\tvalid_1's mape: 0.0173559\n",
      "[1100]\ttraining's mape: 0.0139739\tvalid_1's mape: 0.0172765\n",
      "[1200]\ttraining's mape: 0.0137753\tvalid_1's mape: 0.0171979\n",
      "[1300]\ttraining's mape: 0.0135965\tvalid_1's mape: 0.0171334\n",
      "[1400]\ttraining's mape: 0.0134191\tvalid_1's mape: 0.0170816\n",
      "[1500]\ttraining's mape: 0.0132523\tvalid_1's mape: 0.0170374\n",
      "[1600]\ttraining's mape: 0.0131071\tvalid_1's mape: 0.0170052\n",
      "[1700]\ttraining's mape: 0.0129789\tvalid_1's mape: 0.0169776\n",
      "[1800]\ttraining's mape: 0.0128601\tvalid_1's mape: 0.0169588\n",
      "[1900]\ttraining's mape: 0.0127332\tvalid_1's mape: 0.01694\n",
      "[2000]\ttraining's mape: 0.0126186\tvalid_1's mape: 0.0169339\n",
      "[2100]\ttraining's mape: 0.0125001\tvalid_1's mape: 0.0168944\n",
      "[2200]\ttraining's mape: 0.012398\tvalid_1's mape: 0.0168937\n",
      "[2300]\ttraining's mape: 0.012299\tvalid_1's mape: 0.0168863\n",
      "[2400]\ttraining's mape: 0.012197\tvalid_1's mape: 0.0168725\n",
      "[2500]\ttraining's mape: 0.0120774\tvalid_1's mape: 0.0168487\n",
      "[2600]\ttraining's mape: 0.0119735\tvalid_1's mape: 0.0168423\n",
      "[2700]\ttraining's mape: 0.0118746\tvalid_1's mape: 0.0168239\n",
      "[2800]\ttraining's mape: 0.0117768\tvalid_1's mape: 0.016799\n",
      "[2900]\ttraining's mape: 0.0116891\tvalid_1's mape: 0.0167936\n",
      "[3000]\ttraining's mape: 0.0116056\tvalid_1's mape: 0.0167834\n",
      "[3100]\ttraining's mape: 0.0115252\tvalid_1's mape: 0.0167731\n",
      "[3200]\ttraining's mape: 0.0114491\tvalid_1's mape: 0.0167629\n",
      "[3300]\ttraining's mape: 0.0113778\tvalid_1's mape: 0.0167495\n",
      "[3400]\ttraining's mape: 0.0113063\tvalid_1's mape: 0.0167486\n",
      "Early stopping, best iteration is:\n",
      "[3317]\ttraining's mape: 0.0113653\tvalid_1's mape: 0.0167475\n",
      "fold num_: 8\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's mape: 0.0195178\tvalid_1's mape: 0.0209482\n",
      "[200]\ttraining's mape: 0.0175591\tvalid_1's mape: 0.0195975\n",
      "[300]\ttraining's mape: 0.0166834\tvalid_1's mape: 0.0190772\n",
      "[400]\ttraining's mape: 0.0161031\tvalid_1's mape: 0.0187701\n",
      "[500]\ttraining's mape: 0.0156327\tvalid_1's mape: 0.0185356\n",
      "[600]\ttraining's mape: 0.0152215\tvalid_1's mape: 0.0183377\n",
      "[700]\ttraining's mape: 0.0149052\tvalid_1's mape: 0.0181885\n",
      "[800]\ttraining's mape: 0.0146272\tvalid_1's mape: 0.0181085\n",
      "[900]\ttraining's mape: 0.0143894\tvalid_1's mape: 0.0180419\n",
      "[1000]\ttraining's mape: 0.0141631\tvalid_1's mape: 0.0179579\n",
      "[1100]\ttraining's mape: 0.01397\tvalid_1's mape: 0.0178907\n",
      "[1200]\ttraining's mape: 0.0137823\tvalid_1's mape: 0.0178457\n",
      "[1300]\ttraining's mape: 0.0136069\tvalid_1's mape: 0.0178084\n",
      "[1400]\ttraining's mape: 0.0134494\tvalid_1's mape: 0.017761\n",
      "[1500]\ttraining's mape: 0.0132765\tvalid_1's mape: 0.0177351\n",
      "[1600]\ttraining's mape: 0.0131159\tvalid_1's mape: 0.0177053\n",
      "[1700]\ttraining's mape: 0.0129673\tvalid_1's mape: 0.017677\n",
      "[1800]\ttraining's mape: 0.0128427\tvalid_1's mape: 0.0176383\n",
      "[1900]\ttraining's mape: 0.0127113\tvalid_1's mape: 0.0176103\n",
      "[2000]\ttraining's mape: 0.0126009\tvalid_1's mape: 0.0175945\n",
      "[2100]\ttraining's mape: 0.012483\tvalid_1's mape: 0.0175699\n",
      "[2200]\ttraining's mape: 0.0123769\tvalid_1's mape: 0.017552\n",
      "[2300]\ttraining's mape: 0.0122805\tvalid_1's mape: 0.0175523\n",
      "[2400]\ttraining's mape: 0.0121767\tvalid_1's mape: 0.0175341\n",
      "[2500]\ttraining's mape: 0.0120745\tvalid_1's mape: 0.0175219\n",
      "[2600]\ttraining's mape: 0.0119758\tvalid_1's mape: 0.0175248\n",
      "[2700]\ttraining's mape: 0.0118809\tvalid_1's mape: 0.0175212\n",
      "[2800]\ttraining's mape: 0.0117933\tvalid_1's mape: 0.0175214\n",
      "Early stopping, best iteration is:\n",
      "[2761]\ttraining's mape: 0.0118257\tvalid_1's mape: 0.0175171\n",
      "fold num_: 9\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's mape: 0.0195586\tvalid_1's mape: 0.0206611\n",
      "[200]\ttraining's mape: 0.0176508\tvalid_1's mape: 0.019298\n",
      "[300]\ttraining's mape: 0.0167812\tvalid_1's mape: 0.0188059\n",
      "[400]\ttraining's mape: 0.0161677\tvalid_1's mape: 0.0185003\n",
      "[500]\ttraining's mape: 0.015719\tvalid_1's mape: 0.0182633\n",
      "[600]\ttraining's mape: 0.015342\tvalid_1's mape: 0.0180785\n",
      "[700]\ttraining's mape: 0.0149923\tvalid_1's mape: 0.0179325\n",
      "[800]\ttraining's mape: 0.0147009\tvalid_1's mape: 0.0178188\n",
      "[900]\ttraining's mape: 0.0144155\tvalid_1's mape: 0.0177273\n",
      "[1000]\ttraining's mape: 0.0141877\tvalid_1's mape: 0.017653\n",
      "[1100]\ttraining's mape: 0.0139855\tvalid_1's mape: 0.0175895\n",
      "[1200]\ttraining's mape: 0.0137847\tvalid_1's mape: 0.0175376\n",
      "[1300]\ttraining's mape: 0.0135956\tvalid_1's mape: 0.0174872\n",
      "[1400]\ttraining's mape: 0.013419\tvalid_1's mape: 0.0174539\n",
      "[1500]\ttraining's mape: 0.0132724\tvalid_1's mape: 0.0174131\n",
      "[1600]\ttraining's mape: 0.0131249\tvalid_1's mape: 0.0173865\n",
      "[1700]\ttraining's mape: 0.012989\tvalid_1's mape: 0.017355\n",
      "[1800]\ttraining's mape: 0.0128597\tvalid_1's mape: 0.0173279\n",
      "[1900]\ttraining's mape: 0.0127308\tvalid_1's mape: 0.0173216\n",
      "[2000]\ttraining's mape: 0.0126149\tvalid_1's mape: 0.0173096\n",
      "[2100]\ttraining's mape: 0.0124997\tvalid_1's mape: 0.0172941\n",
      "[2200]\ttraining's mape: 0.0123916\tvalid_1's mape: 0.0172868\n",
      "Early stopping, best iteration is:\n",
      "[2184]\ttraining's mape: 0.0124111\tvalid_1's mape: 0.0172826\n",
      "fold num_: 10\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's mape: 0.0194954\tvalid_1's mape: 0.0207227\n",
      "[200]\ttraining's mape: 0.0175907\tvalid_1's mape: 0.019273\n",
      "[300]\ttraining's mape: 0.0167283\tvalid_1's mape: 0.0187103\n",
      "[400]\ttraining's mape: 0.0161184\tvalid_1's mape: 0.0184012\n",
      "[500]\ttraining's mape: 0.0156585\tvalid_1's mape: 0.0181479\n",
      "[600]\ttraining's mape: 0.0152484\tvalid_1's mape: 0.0179629\n",
      "[700]\ttraining's mape: 0.0149156\tvalid_1's mape: 0.0178332\n",
      "[800]\ttraining's mape: 0.0146318\tvalid_1's mape: 0.0177198\n",
      "[900]\ttraining's mape: 0.0143685\tvalid_1's mape: 0.017628\n",
      "[1000]\ttraining's mape: 0.0141518\tvalid_1's mape: 0.0175647\n",
      "[1100]\ttraining's mape: 0.0139367\tvalid_1's mape: 0.0175116\n",
      "[1200]\ttraining's mape: 0.0137539\tvalid_1's mape: 0.0174526\n",
      "[1300]\ttraining's mape: 0.0135792\tvalid_1's mape: 0.0174166\n",
      "[1400]\ttraining's mape: 0.0134154\tvalid_1's mape: 0.017382\n",
      "[1500]\ttraining's mape: 0.0132633\tvalid_1's mape: 0.0173527\n",
      "[1600]\ttraining's mape: 0.0131265\tvalid_1's mape: 0.0173292\n",
      "[1700]\ttraining's mape: 0.0130017\tvalid_1's mape: 0.0173063\n",
      "[1800]\ttraining's mape: 0.0128833\tvalid_1's mape: 0.0173097\n",
      "[1900]\ttraining's mape: 0.0127632\tvalid_1's mape: 0.0172986\n",
      "[2000]\ttraining's mape: 0.0126435\tvalid_1's mape: 0.0172857\n",
      "[2100]\ttraining's mape: 0.0125287\tvalid_1's mape: 0.0172801\n",
      "[2200]\ttraining's mape: 0.0124163\tvalid_1's mape: 0.0172683\n",
      "Early stopping, best iteration is:\n",
      "[2185]\ttraining's mape: 0.0124326\tvalid_1's mape: 0.0172664\n",
      "\n",
      "Cross Validation Is Complete\n",
      "CPU times: user 9min 25s, sys: 3.19 s, total: 9min 28s\n",
      "Wall time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_ = 10\n",
    "skf = StratifiedKFold(n_splits=n_, shuffle=True, random_state=42)\n",
    "lgb_pred = np.zeros(len(x_test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(skf.split(x_train, x_train['상품군'])):\n",
    "    print(\"fold num_: {}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(x_train.iloc[trn_idx], label=y_train.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(x_train.iloc[val_idx], label=y_train.iloc[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    lgb_model = lgb.train(params = lgb_params,\n",
    "                          train_set = trn_data,\n",
    "                          num_boost_round = num_round,\n",
    "                          valid_sets = [trn_data, val_data],\n",
    "                          verbose_eval = 100,\n",
    "                          categorical_feature = cat_fea,\n",
    "                          early_stopping_rounds = 100)\n",
    "\n",
    "    lgb_pred += lgb_model.predict(x_test, num_iteration=lgb_model.best_iteration) / n_\n",
    "    \n",
    "print('\\nCross Validation Is Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "1kU13LwzmP0-"
   },
   "outputs": [],
   "source": [
    "lgb_pred = np.exp(lgb_pred)\n",
    "lgb_pred = lgb_pred.round(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "-RTRidWhmP1A"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_excel('./02_평가데이터/2020 빅콘테스트 데이터분석분야-챔피언리그_2020년 6월 판매실적예측데이터(평가데이터).xlsx', header=1)\n",
    "submission['취급액'] = lgb_pred\n",
    "submission['취급액'][submission['상품군'] == '무형'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "n7TIQ99OmP1C"
   },
   "outputs": [],
   "source": [
    "submission.to_csv('/submission.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "코드합치기2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
